[Script Info]
; Script generated by Aegisub 3.2.2
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.601
PlayResX: 1280
PlayResY: 720

[Aegisub Project Garbage]
Last Style Storage: Default
Audio File: ../../../Desktop/csapp/Lecture 12  Cache Memories.mp4
Video File: ../../../Desktop/csapp/Lecture 12  Cache Memories.mp4
Video AR Mode: 4
Video AR Value: 1.777778
Video Zoom Percent: 1.000000
Scroll Position: 837
Active Line: 847
Video Position: 141216

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1
Style: csapp,Source Han Sans CN,34,&H00FFFFFF,&H00FFFFFF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:04.16,csapp,,0,0,0,,good afternoon everyone welcome to 213 it's good to see you
Dialogue: 0,0:00:06.14,0:00:12.46,csapp,,0,0,0,,just a reminder that your attack lab is due tonight at 11:59 p.m.
Dialogue: 0,0:00:13.22,0:00:16.18,csapp,,0,0,0,,you have one grace day for this for this lab
Dialogue: 0,0:00:17.00,0:00:19.82,csapp,,0,0,0,,and cache lab we'll go out it right about the same time
Dialogue: 0,0:00:21.36,0:00:25.68,csapp,,0,0,0,,now it's going to be a little tight for cash labs it'll be due next Thursday
Dialogue: 0,0:00:27.04,0:00:29.84,csapp,,0,0,0,,so you might want to you might want to get started on that soon
Dialogue: 0,0:00:32.92,0:00:36.90,csapp,,0,0,0,,last lecture we learned about the memory hierarchy and the idea of caching
Dialogue: 0,0:00:37.54,0:00:41.24,csapp,,0,0,0,,today we're going to look at a very important kind of cache
Dialogue: 0,0:00:43.28,0:00:46.22,csapp,,0,0,0,,which is a which are which are called cache memories
Dialogue: 0,0:00:47.40,0:00:49.96,csapp,,0,0,0,,and they're very important to you as a programmer
Dialogue: 0,0:00:49.96,0:00:53.40,csapp,,0,0,0,,because they can have such a big impact on the performance of your program
Dialogue: 0,0:00:53.96,0:00:57.87,csapp,,0,0,0,,so if you know about these the existence of these cache memories and you know how they work
Dialogue: 0,0:00:59.30,0:01:02.20,csapp,,0,0,0,,as a programmer you'll be able to take advantage of that in your programs
Dialogue: 0,0:01:08.42,0:01:18.62,csapp,,0,0,0,,so last time we looked at the memory hierarchy is a collection of storage devices with smaller costlier
Dialogue: 0,0:01:20.94,0:01:24.36,csapp,,0,0,0,,devices at the and faster devices at the top and
Dialogue: 0,0:01:25.08,0:01:31.02,csapp,,0,0,0,,slower cheaper and much larger devices at the at the bottom
Dialogue: 0,0:01:32.04,0:01:34.80,csapp,,0,0,0,,and then at each level in this hierarchy
Dialogue: 0,0:01:35.48,0:01:42.76,csapp,,0,0,0,,the device at level K serves as a cache holds a subset of the blocks of
Dialogue: 0,0:01:43.28,0:01:47.92,csapp,,0,0,0,,that are contained in the device at the lower level at level k+1
Dialogue: 0,0:01:52.06,0:01:55.94,csapp,,0,0,0,,now recall the general idea of caching so we have a memory
Dialogue: 0,0:01:57.10,0:02:01.70,csapp,,0,0,0,,it's an array of bytes and it's it's we we break it up arbitrarily into a collection of blocks
Dialogue: 0,0:02:03.52,0:02:08.30,csapp,,0,0,0,,and these this memory is larger slower and cheaper
Dialogue: 0,0:02:08.48,0:02:14.98,csapp,,0,0,0,,and so it's and it's much larger than than a cache which is smaller faster and more expensive
Dialogue: 0,0:02:15.76,0:02:20.82,csapp,,0,0,0,,and which holds and which holds a subset of the blocks that are contained in the main memory
Dialogue: 0,0:02:22.66,0:02:27.96,csapp,,0,0,0,,and then blocks are copied back and forth between the cache in the memory in these block size transfer units
Dialogue: 0,0:02:29.00,0:02:35.62,csapp,,0,0,0,,so for example if our program requests a word that's in contained in block number 4
Dialogue: 0,0:02:38.16,0:02:43.30,csapp,,0,0,0,, it asks the cache to return the word that's contained in block 4
Dialogue: 0,0:02:43.90,0:02:48.16,csapp,,0,0,0,,the cache looks and it's at the blocks that it's the subset of the blocks
Dialogue: 0,0:02:48.16,0:02:51.34,csapp,,0,0,0,,that it's stored discovers that block 4 is not there
Dialogue: 0,0:02:52.04,0:02:54.44,csapp,,0,0,0,,so it asks the main memory to send it block 4
Dialogue: 0,0:02:55.00,0:02:59.40,csapp,,0,0,0,,which it does and when that block arrives at the cache
Dialogue: 0,0:02:59.90,0:03:04.30,csapp,,0,0,0,,the cache stores it but potentially overwriting some existing block
Dialogue: 0,0:03:05.04,0:03:08.48,csapp,,0,0,0,,similarly if our program asks for a data word
Dialogue: 0,0:03:09.08,0:03:10.74,csapp,,0,0,0,, if that's contained within block 10
Dialogue: 0,0:03:11.42,0:03:14.24,csapp,,0,0,0,, the cache looks sees that it doesn't have that block
Dialogue: 0,0:03:14.58,0:03:19.04,csapp,,0,0,0,,so it requests that block for memory which copies it into the cache
Dialogue: 0,0:03:19.77,0:03:22.58,csapp,,0,0,0,,which overwrites an existing block
Dialogue: 0,0:03:23.40,0:03:28.86,csapp,,0,0,0,,now subsequently if our program asks for a request
Dialogue: 0,0:03:29.04,0:03:32.56,csapp,,0,0,0,, or if our program references a word that's contained in block 10
Dialogue: 0,0:03:32.62,0:03:38.98,csapp,,0,0,0,,for example then the cache then we have a hit and the cache can return that block immediately
Dialogue: 0,0:03:39.34,0:03:43.50,csapp,,0,0,0,,without going through the expensive operation of contacting memory
Dialogue: 0,0:03:43.76,0:03:45.94,csapp,,0,0,0,,and fetching that block from memory
Dialogue: 0,0:03:50.22,0:03:54.95,csapp,,0,0,0,,now there's a very important class of caches these so called cache memories
Dialogue: 0,0:03:55.80,0:03:59.12,csapp,,0,0,0,,which are contained in the CPU chip itself
Dialogue: 0,0:04:00.02,0:04:01.98,csapp,,0,0,0,,and are managed completely by Hardware
Dialogue: 0,0:04:02.56,0:04:05.88,csapp,,0,0,0,,and they're implemented using fast SRAM memories
Dialogue: 0,0:04:07.56,0:04:11.88,csapp,,0,0,0,,and the idea for this cache which write next to the register file
Dialogue: 0,0:04:13.50,0:04:18.50,csapp,,0,0,0,, is to hold frequently access blocks or blocks from main memory that are accessed frequently
Dialogue: 0,0:04:19.06,0:04:22.40,csapp,,0,0,0,,okay so hopefully because of the principle of locality
Dialogue: 0,0:04:23.20,0:04:31.02,csapp,,0,0,0,, most of our requests for data will actually be served out of this cache memory and a few cycles
Dialogue: 0,0:04:31.48,0:04:35.32,csapp,,0,0,0,,rather than from this slow main memory
Dialogue: 0,0:04:40.40,0:04:43.04,csapp,,0,0,0,,now cache memories are managed completely in Hardware
Dialogue: 0,0:04:44.00,0:04:49.32,csapp,,0,0,0,,so this means that the heart there's there has to be Hardware logic that knows
Dialogue: 0,0:04:49.80,0:04:55.62,csapp,,0,0,0,,how to look for blocks in the cache and determine whether or not a particular block is contained there
Dialogue: 0,0:04:55.62,0:05:00.96,csapp,,0,0,0,,so cache memories are have to be organized in a very kind of strict simple  way
Dialogue: 0,0:05:00.96,0:05:03.80,csapp,,0,0,0,,so that the logic the lookup logic can be pretty simple
Dialogue: 0,0:05:04.78,0:05:10.22,csapp,,0,0,0,,so this is very all cache memories are organized within the following way
Dialogue: 0,0:05:11.00,0:05:17.76,csapp,,0,0,0,,you can think of that you can think of the cache as an array of s equals 2 to the S sets
Dialogue: 0,0:05:20.35,0:05:25.12,csapp,,0,0,0,, ok each set consists of e to the to e lines
Dialogue: 0,0:05:28.60,0:05:33.92,csapp,,0,0,0,,where each line consists of a block of B
Dialogue: 0,0:05:35.10,0:05:37.48,csapp,,0,0,0,,it equals 2 to the B bytes of data
Dialogue: 0,0:05:39.48,0:05:48.68,csapp,,0,0,0,, a valid bit which indicates whether these data bits are actually that the bits and the data block are actually meaningful right
Dialogue: 0,0:05:49.30,0:05:53.78,csapp,,0,0,0,, it's possible they could just be random bits like you know when you first turn on the machine
Dialogue: 0,0:05:54.20,0:05:55.50,csapp,,0,0,0,,there's nothing in the cache
Dialogue: 0,0:05:56.12,0:05:59.58,csapp,,0,0,0,,but those bits will have values right that they'll lead to be ones or zeros
Dialogue: 0,0:05:59.58,0:06:01.36,csapp,,0,0,0,,but they won't actually correspond to data
Dialogue: 0,0:06:01.94,0:06:08.28,csapp,,0,0,0,,okay so the valid bit tells us if these if these be bytes actually mean anything
Dialogue: 0,0:06:09.14,0:06:11.94,csapp,,0,0,0,,and then there's some additional bits called the tag bits
Dialogue: 0,0:06:12.52,0:06:16.53,csapp,,0,0,0,,which will help us search for blocks which I'll show you in a minute
Dialogue: 0,0:06:17.44,0:06:19.26,csapp,,0,0,0,,now when we talk about our cache size
Dialogue: 0,0:06:19.92,0:06:25.40,csapp,,0,0,0,,we're referring to the number of data bytes that are contained in blocks
Dialogue: 0,0:06:26.88,0:06:31.60,csapp,,0,0,0,,and so each cache has there's s sets
Dialogue: 0,0:06:32.84,0:06:36.32,csapp,,0,0,0,,there's e e blocks per set
Dialogue: 0,0:06:36.98,0:06:38.46,csapp,,0,0,0,,and there's B bytes per block
Dialogue: 0,0:06:38.56,0:06:42.96,csapp,,0,0,0,,ok so the total cache size C=S*E*B
Dialogue: 0,0:06:44.44,0:06:49.36,csapp,,0,0,0,,ok now so there's a lot of terms to sort of keep straight and it's very easy to get
Dialogue: 0,0:06:50.42,0:06:55.54,csapp,,0,0,0,,to confuse the difference between lines and blocks  and lines and sets okay
Dialogue: 0,0:06:56.14,0:07:01.42,csapp,,0,0,0,,so we'll go through some examples and hopefully these will see these will start to make more sense
Dialogue: 0,0:07:03.06,0:07:11.00,csapp,,0,0,0,,now let's look at in general how we how the cache Hardware implements a read
Dialogue: 0,0:07:12.26,0:07:17.02,csapp,,0,0,0,,so when our program accesses when our program executes an instruction
Dialogue: 0,0:07:17.88,0:07:20.80,csapp,,0,0,0,,that references some word in memory
Dialogue: 0,0:07:22.66,0:07:26.88,csapp,,0,0,0,,the the CPU sends that address to the cache
Dialogue: 0,0:07:27.16,0:07:34.44,csapp,,0,0,0,,and asks and it asks the cache to return the word the word at that address
Dialogue: 0,0:07:37.00,0:07:39.24,csapp,,0,0,0,,so the cache takes that address
Dialogue: 0,0:07:41.38,0:07:46.02,csapp,,0,0,0,,this would be a 64-bit address in case of x86 64
Dialogue: 0,0:07:47.12,0:07:52.36,csapp,,0,0,0,,and it it divides the address into a number of of regions
Dialogue: 0,0:07:52.98,0:07:56.18,csapp,,0,0,0,,which are which are determined by the organization of the cache
Dialogue: 0,0:07:56.96,0:08:01.24,csapp,,0,0,0,,okay they're determined by those parameters s sets
Dialogue: 0,0:08:01.86,0:08:07.48,csapp,,0,0,0,,the s the number of sets a the number of lines per set and B the size of each data block
Dialogue: 0,0:08:09.04,0:08:15.82,csapp,,0,0,0,,so the low order bits there are B low order bits which determine the offset in the block
Dialogue: 0,0:08:16.18,0:08:17.68,csapp,,0,0,0,,that that word starts at
Dialogue: 0,0:08:20.36,0:08:25.88,csapp,,0,0,0,,okay the next s fits are treated as an unsigned integer
Dialogue: 0,0:08:26.42,0:08:30.20,csapp,,0,0,0,,which serves as an index into the array of sets
Dialogue: 0,0:08:31.02,0:08:34.74,csapp,,0,0,0,,okay remember we just think of these as think of this cache as an array of set
Dialogue: 0,0:08:35.78,0:08:41.30,csapp,,0,0,0,,the set index bits provide the index into the into this array of sets
Dialogue: 0,0:08:42.12,0:08:43.74,csapp,,0,0,0,,and then all of the remaining bits
Dialogue: 0,0:08:46.06,0:08:51.14,csapp,,0,0,0,,all of the remaining T bits constitute what we call a tag
Dialogue: 0,0:08:51.56,0:08:53.22,csapp,,0,0,0,,which will help us when we do our search
Dialogue: 0,0:08:54.40,0:08:56.68,csapp,,0,0,0,,so the cache logic takes this address
Dialogue: 0,0:08:58.42,0:09:01.14,csapp,,0,0,0,,and it first extracts the the set index
Dialogue: 0,0:09:01.42,0:09:06.66,csapp,,0,0,0,,and uses that to as an index into this array to identify the set that
Dialogue: 0,0:09:07.20,0:09:11.32,csapp,,0,0,0,, if this block is in the set I'm sorry if the data word
Dialogue: 0,0:09:12.20,0:09:15.98,csapp,,0,0,0,,if the block that contains the data word at this address
Dialogue: 0,0:09:16.80,0:09:23.54,csapp,,0,0,0,,is in the cache it's going to be in the set denoted by the the set index
Dialogue: 0,0:09:27.16,0:09:30.52,csapp,,0,0,0,,so first it identifies which index to look in
Dialogue: 0,0:09:36.28,0:09:41.80,csapp,,0,0,0,,and then it checks the tag it checks all of the lines in that set
Dialogue: 0,0:09:43.30,0:09:46.66,csapp,,0,0,0,,to see if there's any any of those lines have a matching tag
Dialogue: 0,0:09:46.88,0:09:50.88,csapp,,0,0,0,,that a tag that matches the the T the tag bits and the address okay
Dialogue: 0,0:09:53.58,0:09:56.52,csapp,,0,0,0,,and if and it checks to see if the valid bit is turned on
Dialogue: 0,0:09:56.52,0:09:59.70,csapp,,0,0,0,, so if those two conditions holds if there's a line anywhere in the set
Dialogue: 0,0:10:00.28,0:10:05.30,csapp,,0,0,0,,as of where the valid bit is is is one and there's a matching tag
Dialogue: 0,0:10:06.06,0:10:10.84,csapp,,0,0,0,,then we have a hit okay then the block that we're looking for is contained in this set
Dialogue: 0,0:10:15.58,0:10:20.42,csapp,,0,0,0,,okay if we once we determine that with that we've identified the block
Dialogue: 0,0:10:20.72,0:10:25.48,csapp,,0,0,0,,then the cache uses that the low-order B bits  to determine where that
Dialogue: 0,0:10:26.40,0:10:30.28,csapp,,0,0,0,,where the data we're interested in begins okay within that block
Dialogue: 0,0:10:32.38,0:10:37.24,csapp,,0,0,0,,all right let's look at a more specific example for a the simplest kind of cache
Dialogue: 0,0:10:38.00,0:10:42.00,csapp,,0,0,0,,which is when e equals one when there's only one line per set
Dialogue: 0,0:10:43.68,0:10:46.12,csapp,,0,0,0,,okay so a equal one one line per set
Dialogue: 0,0:10:46.78,0:10:49.04,csapp,,0,0,0,,this kind of cache is called a direct mapped cache
Dialogue: 0,0:10:52.26,0:10:55.98,csapp,,0,0,0,,so here we have s sets each set consists of a single line
Dialogue: 0,0:10:56.64,0:11:00.74,csapp,,0,0,0,,and now suppose our program references the data item
Dialogue: 0,0:11:01.02,0:11:06.52,csapp,,0,0,0,, and a particular address the CPU sense that address to the cache
Dialogue: 0,0:11:07.20,0:11:11.68,csapp,,0,0,0,, the cache takes that address breaks it up into these into these three fields
Dialogue: 0,0:11:12.76,0:11:17.92,csapp,,0,0,0,, in the in for this particular address the the block offset is four
Dialogue: 0,0:11:19.46,0:11:26.30,csapp,,0,0,0,,and the set index is one and then there's some tag bits which we'll just denote with with is a color pink
Dialogue: 0,0:11:28.04,0:11:33.02,csapp,,0,0,0,,so the cache extracts the set index which is one
Dialogue: 0,0:11:33.16,0:11:36.46,csapp,,0,0,0,,and then it uses that as as the index into the set
Dialogue: 0,0:11:42.00,0:11:44.94,csapp,,0,0,0,,and then it can just it just ignores all the other the sets
Dialogue: 0,0:11:45.62,0:11:50.65,csapp,,0,0,0,,if the block we're looking for is is in the cache it's going to be in this inset number one
Dialogue: 0,0:11:51.50,0:11:54.84,csapp,,0,0,0,,then it does the comparison of the tag bits and the valid bits
Dialogue: 0,0:11:55.42,0:11:58.64,csapp,,0,0,0,, and assume that they assume that valid bits on and that it matches
Dialogue: 0,0:12:00.16,0:12:02.54,csapp,,0,0,0,,  then it looks at the block offset which is four
Dialogue: 0,0:12:03.94,0:12:11.76,csapp,,0,0,0,,and which tells it that the four by ten suppose that that's what the instruction was referencing
Dialogue: 0,0:12:12.28,0:12:14.82,csapp,,0,0,0,,the four byte in begins that offset for
Dialogue: 0,0:12:15.28,0:12:22.38,csapp,,0,0,0,,so now the cache takes takes this int and it sends it back to the to the CPU which puts it in the register
Dialogue: 0,0:12:28.96,0:12:36.22,csapp,,0,0,0,,okay if the tag doesn't match then the old-line if the tag doesn't match then there's a miss
Dialogue: 0,0:12:38.16,0:12:43.64,csapp,,0,0,0,,and in that case the cache has to fetch the block the corresponding block from memory
Dialogue: 0,0:12:44.36,0:12:47.68,csapp,,0,0,0,,and then overwrite this block in the line
Dialogue: 0,0:12:48.98,0:12:55.92,csapp,,0,0,0,,and then it can serve then it can fetch it can get the word out of the block and send it back to the processor
Dialogue: 0,0:12:57.80,0:13:02.24,csapp,,0,0,0,,okay now let me ask you a question just to see if kind of check to see if you're following along with this
Dialogue: 0,0:13:03.22,0:13:04.20,csapp,,0,0,0,,so if there's a Miss
Dialogue: 0,0:13:05.34,0:13:09.10,csapp,,0,0,0,,and the cache has two requests the block for memory
Dialogue: 0,0:13:09.90,0:13:14.34,csapp,,0,0,0,,fetch it from memory and then overwrite the the block in the current line
Dialogue: 0,0:13:16.54,0:13:22.18,csapp,,0,0,0,,does it also have to change the tag bits  or do those stay the same
Dialogue: 0,0:13:22.18,0:13:28.58,csapp,,0,0,0,,so does the do the tag bits that were in this line get overwritten with a different value
Dialogue: 0,0:13:30.04,0:13:39.42,csapp,,0,0,0,,or is it the same? same? different? same? different?
Dialogue: 0,0:13:43.70,0:13:44.98,csapp,,0,0,0,,now why would it be different ?
Dialogue: 0,0:13:48.46,0:13:59.24,csapp,,0,0,0,,-we haven't changed yes I'm sorry oh
Dialogue: 0,0:13:59.54,0:14:02.52,csapp,,0,0,0,,-it it almost certainly has different data
Dialogue: 0,0:14:02.92,0:14:04.16,csapp,,0,0,0,,but does it have a different address
Dialogue: 0,0:14:13.24,0:14:17.60,csapp,,0,0,0,,exactly it missed it missed because the tag
Dialogue: 0,0:14:18.18,0:14:19.82,csapp,,0,0,0,,it missed because the tag didn't match
Dialogue: 0,0:14:22.90,0:14:26.94,csapp,,0,0,0,,if the valid bit was false and the tag match then then that would also be a miss
Dialogue: 0,0:14:28.74,0:14:34.74,csapp,,0,0,0,,oh then you wouldn't okay that's right that's okay good good good okay great
Dialogue: 0,0:14:39.70,0:14:48.10,csapp,,0,0,0,,all right let me do a little let me do a really simple specific example of a how direct map cache works
Dialogue: 0,0:14:48.92,0:14:53.56,csapp,,0,0,0,, I want you to understand in real detail how this would work
Dialogue: 0,0:14:53.56,0:14:59.42,csapp,,0,0,0,,but I also want to make a point for about the weakness of direct mapped cache --is and why
Dialogue: 0,0:15:00.08,0:15:02.62,csapp,,0,0,0,,why you would want to have more than one line per set
Dialogue: 0,0:15:04.96,0:15:11.48,csapp,,0,0,0,,okay so we this is a really simple our met we have our memory system consists of 16 bytes
Dialogue: 0,0:15:11.70,0:15:15.30,csapp,,0,0,0,, ok so it's not a very useful system with 4 bit addresses
Dialogue: 0,0:15:16.94,0:15:20.42,csapp,,0,0,0,,and and it's broken up into blocks of 2 bytes each
Dialogue: 0,0:15:21.74,0:15:26.34,csapp,,0,0,0,,our cache consists of 4 sets with one block per set
Dialogue: 0,0:15:28.32,0:15:31.26,csapp,,0,0,0,,now our 4 by our fort bit addresses
Dialogue: 0,0:15:33.08,0:15:38.56,csapp,,0,0,0,,because be equal to that's 2 to the 1 we only need 1 block offset bit right
Dialogue: 0,0:15:38.80,0:15:44.74,csapp,,0,0,0,, there's only 2 bytes in a block so the byte we're looking for is either at 0 or 1
Dialogue: 0,0:15:46.80,0:15:51.82,csapp,,0,0,0,,okay because we have 4 sets we need to set off set index bits
Dialogue: 0,0:15:52.52,0:15:57.20,csapp,,0,0,0,,and then the remaining bits are always tag bits in this case there's just one tag bit
Dialogue: 0,0:15:58.66,0:16:05.38,csapp,,0,0,0,,all right now let's suppose that our program executes instructions that
Dialogue: 0,0:16:05.54,0:16:12.30,csapp,,0,0,0,,that reference the following memory address is 0 1 7 8 and 0
Dialogue: 0,0:16:14.10,0:16:18.34,csapp,,0,0,0,, and these references are reads that they're reading one byte per read
Dialogue: 0,0:16:19.04,0:16:20.92,csapp,,0,0,0,,okay like I said this is a really simple system
Dialogue: 0,0:16:23.46,0:16:24.90,csapp,,0,0,0,,so let's look at what happens now
Dialogue: 0,0:16:24.90,0:16:33.82,csapp,,0,0,0,, we start out our tag our initially our our cache is empty valid bits are all set to zero
Dialogue: 0,0:16:35.76,0:16:40.64,csapp,,0,0,0,,and now the cache receives the request for the byte that's at address 0
Dialogue: 0,0:16:43.02,0:16:46.90,csapp,,0,0,0,,so it extracts the set index bits which in this case are 0 0
Dialogue: 0,0:16:47.96,0:16:51.02,csapp,,0,0,0,,so these so it's going to look in set 0
Dialogue: 0,0:16:52.58,0:16:58.36,csapp,,0,0,0,, for and in this case since valid is 0 it's just it's it's a Miss ok
Dialogue: 0,0:16:59.76,0:17:04.64,csapp,,0,0,0,,so it fetches that block from memory sticks the block
Dialogue: 0,0:17:06.04,0:17:11.60,csapp,,0,0,0,,so this memory this is the DS it this is using array notation for memory
Dialogue: 0,0:17:11.60,0:17:18.78,csapp,,0,0,0,,so this is like the the bytes that extend from offset 0 to offset 1 inclusive in memory
Dialogue: 0,0:17:20.84,0:17:25.42,csapp,,0,0,0,,the tag bit is 0 and the valid bit is 1
Dialogue: 0,0:17:26.14,0:17:30.76,csapp,,0,0,0,,ok now the next the next address that comes by is for address 1
Dialogue: 0,0:17:32.86,0:17:40.14,csapp,,0,0,0,, well that's a hit right because we that block the block that contains the byte at address 1 is already in the cache
Dialogue: 0,0:17:41.82,0:17:45.62,csapp,,0,0,0,, the tag and the tags match okay so we're good that's a hit
Dialogue: 0,0:17:47.16,0:17:48.64,csapp,,0,0,0,,you now we get address 7
Dialogue: 0,0:17:50.62,0:17:57.72,csapp,,0,0,0,,so the cache extracts the set index bits which in this case are 1 1 or 4 or 3 rather
Dialogue: 0,0:17:59.80,0:18:07.42,csapp,,0,0,0,,looks in set 3 there's no valid bit so that's a Miss and it loads the the data from memory
Dialogue: 0,0:18:08.22,0:18:11.14,csapp,,0,0,0,,that spans bytes 6 & 7
Dialogue: 0,0:18:13.04,0:18:16.68,csapp,,0,0,0,,in this case the the tag bit is 0
Dialogue: 0,0:18:17.74,0:18:21.20,csapp,,0,0,0,,okay so we record that we record that in our metadata
Dialogue: 0,0:18:22.84,0:18:24.98,csapp,,0,0,0,,okay the next reference that comes by is 8
Dialogue: 0,0:18:27.06,0:18:31.02,csapp,,0,0,0,,now 8 has a set index of 0 0 0
Dialogue: 0,0:18:31.84,0:18:36.70,csapp,,0,0,0,,but that's currently occupied by block zero one
Dialogue: 0,0:18:37.20,0:18:41.96,csapp,,0,0,0,,and we can tell that because address eight has a tag of one
Dialogue: 0,0:18:42.40,0:18:49.70,csapp,,0,0,0,,and the existing block of the block at the earlier address at address zero has a tag of zero so that's a miss so
Dialogue: 0,0:18:51.32,0:18:58.82,csapp,,0,0,0,,so now we have to go fetch the block containing byte number eight into memory
Dialogue: 0,0:18:58.82,0:19:03.88,csapp,,0,0,0,,so now we have bytes eight and nine and we in our new tag bit
Dialogue: 0,0:19:05.82,0:19:11.12,csapp,,0,0,0,, okay now the next instruction is for byte 0
Dialogue: 0,0:19:12.62,0:19:18.30,csapp,,0,0,0,,and we just we just replaced we had that it we had that in our cache and we just replaced it
Dialogue: 0,0:19:19.76,0:19:22.32,csapp,,0,0,0,,so it's another miss so that's unfortunate
Dialogue: 0,0:19:23.24,0:19:30.02,csapp,,0,0,0,,and it's the only reason we missed it is because we've got just one line per set
Dialogue: 0,0:19:31.06,0:19:33.00,csapp,,0,0,0,, right so we were forced to overwrite
Dialogue: 0,0:19:38.22,0:19:45.92,csapp,,0,0,0,,that that block containing bytes the block zero one when we when we missed on on block eight nine
Dialogue: 0,0:19:47.88,0:19:54.14,csapp,,0,0,0,,okay so this and you see there's plenty of room in our cache we've still got we've got two two lines
Dialogue: 0,0:19:54.78,0:19:58.96,csapp,,0,0,0,, that we haven't even access right so we've our cache is plenty big
Dialogue: 0,0:19:59.62,0:20:04.54,csapp,,0,0,0,,but just because of the sort of the low associativity of our cache
Dialogue: 0,0:20:05.18,0:20:08.96,csapp,,0,0,0,,and the the sort of the pattern the access pattern that we were presented with
Dialogue: 0,0:20:09.36,0:20:12.88,csapp,,0,0,0,,we've got a Miss that really was kind of unnecessary
Dialogue: 0,0:20:13.58,0:20:29.06,csapp,,0,0,0,, so oh yeah sorry
Dialogue: 0,0:20:29.10,0:20:34.20,csapp,,0,0,0,,six so when we referenced when we referenced a seven
Dialogue: 0,0:20:35.26,0:20:40.72,csapp,,0,0,0,, it's actually the it's at offset one in that block six seven
Dialogue: 0,0:20:41.50,0:20:45.38,csapp,,0,0,0,,okay since our blocks are two bytes they'll always start on an even multiple
Dialogue: 0,0:20:51.58,0:20:52.80,csapp,,0,0,0,,any other questions
Dialogue: 0,0:20:57.64,0:21:06.78,csapp,,0,0,0,,okay so this sort of is the reason why you have caches have higher associativity higher values of e
Dialogue: 0,0:21:08.24,0:21:17.96,csapp,,0,0,0,,so let's look at and and so for for values of e greater for values of e greater than greater than 1
Dialogue: 0,0:21:19.22,0:21:22.98,csapp,,0,0,0,,we refer to them as a way so she set associative caches
Dialogue: 0,0:21:24.34,0:21:27.92,csapp,,0,0,0,,so here e equals 2 so it's a 2-way it's 2-way associative
Dialogue: 0,0:21:30.44,0:21:36.00,csapp,,0,0,0,,let's let's suppose we have a 2-way a 2-way associative cache
Dialogue: 0,0:21:36.00,0:21:43.94,csapp,,0,0,0,,so here we have our array of sets and now each set contains two lines ok instead of one line
Dialogue: 0,0:21:46.28,0:21:51.18,csapp,,0,0,0,,and suppose we're presented with an address with the following form
Dialogue: 0,0:21:53.50,0:21:58.40,csapp,,0,0,0,,we're looking for the word that begins at an off set of four inside our block
Dialogue: 0,0:22:01.04,0:22:05.20,csapp,,0,0,0,,at within set number one
Dialogue: 0,0:22:08.04,0:22:11.00,csapp,,0,0,0,,okay so the cache expects tracts that set index
Dialogue: 0,0:22:12.02,0:22:20.34,csapp,,0,0,0,,so this is set 0 this is set 1 this is set 2 throws away all the other sets
Dialogue: 0,0:22:21.50,0:22:33.58,csapp,,0,0,0,,and now in parallel it searches it searches the tags it searches for a matching tag in both of these both of these lines
Dialogue: 0,0:22:35.18,0:22:40.22,csapp,,0,0,0,,and ant a valid bit so if we get a matching tag and a valid bit true
Dialogue: 0,0:22:40.74,0:22:45.06,csapp,,0,0,0,,then we've got a a then we've got a hit
Dialogue: 0,0:22:47.26,0:22:56.84,csapp,,0,0,0,,now that yes yes
Dialogue: 0,0:22:56.92,0:23:01.60,csapp,,0,0,0,,oh it's a very good question so there's there's hardware logic that does that compare
Dialogue: 0,0:23:02.60,0:23:09.82,csapp,,0,0,0,,and it's and that's the reason that as as the number of as the associativity goes up that logic gets more and more expensive
Dialogue: 0,0:23:10.78,0:23:15.42,csapp,,0,0,0,,okay it's like something like you're kind of doing some kind of tree
Dialogue: 0,0:23:16.50,0:23:20.84,csapp,,0,0,0,,search and so that actually is the limit that's why I mean because in general
Dialogue: 0,0:23:21.46,0:23:25.04,csapp,,0,0,0,,right that if you take this to the limit there's just one set
Dialogue: 0,0:23:26.36,0:23:32.24,csapp,,0,0,0,,with there's just it's we call that a fully associative cache so there's just one set
Dialogue: 0,0:23:33.08,0:23:35.74,csapp,,0,0,0,,and now any block a block can go anywhere
Dialogue: 0,0:23:36.16,0:23:38.44,csapp,,0,0,0,,right there's no constraints now where you place a block
Dialogue: 0,0:23:39.66,0:23:44.74,csapp,,0,0,0,,but the because of the complexity of that that fully associative search
Dialogue: 0,0:23:45.10,0:23:53.22,csapp,,0,0,0,,those are very rare in fact you we do see we'll see fully associative caches but their software caches
Dialogue: 0,0:23:54.70,0:23:59.12,csapp,,0,0,0,,okay so in software and so the the complexity the hardware
Dialogue: 0,0:23:59.90,0:24:03.40,csapp,,0,0,0,,and sort of doesn't doesn't
Dialogue: 0,0:24:05.22,0:24:12.06,csapp,,0,0,0,,doesn't it's not worth the complexity of the hardware for the penalty of having a lower associativity
Dialogue: 0,0:24:12.78,0:24:16.24,csapp,,0,0,0,,okay but there are some systems later on when we study virtual memory
Dialogue: 0,0:24:17.20,0:24:23.74,csapp,,0,0,0,,the in a virtual memory system the DRAM serves as a cache for data stored on the disk
Dialogue: 0,0:24:24.78,0:24:28.04,csapp,,0,0,0,,and as we saw last time the penalty for a miss
Dialogue: 0,0:24:28.88,0:24:32.22,csapp,,0,0,0,,if you have a cache on DRAM and you miss and you have to go to disk
Dialogue: 0,0:24:32.96,0:24:34.68,csapp,,0,0,0,,the penalty is huge for that
Dialogue: 0,0:24:35.14,0:24:42.74,csapp,,0,0,0,, and so because of that it's worth while having very complex searches search algorithms
Dialogue: 0,0:24:42.96,0:24:47.02,csapp,,0,0,0,,in particular in a virtual memory system that the DRAM
Dialogue: 0,0:24:47.50,0:24:51.11,csapp,,0,0,0,,is implements a fully associative cache where blocks from disk can go anywhere
Dialogue: 0,0:24:51.52,0:24:54.40,csapp,,0,0,0,, we'll get into that later when we look in in virtual memory
Dialogue: 0,0:24:54.60,0:24:56.22,csapp,,0,0,0,,but you're right you'll see in real systems
Dialogue: 0,0:24:56.70,0:25:01.16,csapp,,0,0,0,,nowadays that the number goes up right because feature sizes are going down and
Dialogue: 0,0:25:01.56,0:25:04.86,csapp,,0,0,0,,designers can afford to implement more expensive hardware
Dialogue: 0,0:25:04.86,0:25:12.02,csapp,,0,0,0,,but the the largest associativity are Intel systems that I know of is 16-way associative l3 caches
Dialogue: 0,0:25:12.60,0:25:17.28,csapp,,0,0,0,,and then the others are eight ways so she tips so that's sort of the order of magnitude that's state of the art right now
Dialogue: 0,0:25:20.76,0:25:25.24,csapp,,0,0,0,,okay so then once we've identified a match we use the set offset bits
Dialogue: 0,0:25:26.46,0:25:33.20,csapp,,0,0,0,, in this case we're accessing a short in so four is the offset within the block of this
Dialogue: 0,0:25:33.90,0:25:37.48,csapp,,0,0,0,,the two byte short int which then we can return to the processor
Dialogue: 0,0:25:39.44,0:25:42.02,csapp,,0,0,0,,alright so let's do that same simulation that we did before
Dialogue: 0,0:25:42.02,0:25:46.10,csapp,,0,0,0,,but this time with a two way associative cache
Dialogue: 0,0:25:46.78,0:25:52.94,csapp,,0,0,0,, now memory system is the same but now instead of one set we have two sets
Dialogue: 0,0:25:54.50,0:25:58.86,csapp,,0,0,0,,and I mean I'm sorry instead of four sets we have two sets
Dialogue: 0,0:25:58.94,0:26:04.26,csapp,,0,0,0,, so the cache this is the same sized cache but we're just going to organize it differently
Dialogue: 0,0:26:04.38,0:26:07.12,csapp,,0,0,0,,okay instead of one way instead of a direct mapped cache
Dialogue: 0,0:26:08.36,0:26:12.00,csapp,,0,0,0,,with four lines containing four lines one line per set
Dialogue: 0,0:26:12.48,0:26:18.50,csapp,,0,0,0,,we're going to implement a 2-way associative cache where we have two sets with two lines per set
Dialogue: 0,0:26:18.68,0:26:22.10,csapp,,0,0,0,,okay so each case there's just four there's four total lines
Dialogue: 0,0:26:22.46,0:26:29.80,csapp,,0,0,0,,question
Dialogue: 0,0:26:29.80,0:26:34.78,csapp,,0,0,0,,like oh so that that comes in with the request somehow and I actually don't know the details of that
Dialogue: 0,0:26:35.90,0:26:42.82,csapp,,0,0,0,, it may I guess there so it could ask for just there could just be a default sighs maybe it's always
Dialogue: 0,0:26:43.68,0:26:48.84,csapp,,0,0,0,,it's always a 64-byte word and then the processor extracts that the current bits
Dialogue: 0,0:26:48.84,0:26:55.98,csapp,,0,0,0,,I actually don't know the details of that but it either comes in on the request or or there's a standard
Dialogue: 0,0:26:56.16,0:26:59.10,csapp,,0,0,0,,there's a standard size that the processor then parses out
Dialogue: 0,0:27:01.46,0:27:05.00,csapp,,0,0,0,, we'll just assume that the cache knows the what size to return yes
Dialogue: 0,0:27:05.22,0:27:08.80,csapp,,0,0,0,,[student speaking]
Dialogue: 0,0:27:08.82,0:27:12.06,csapp,,0,0,0,, how do you decide which block to replace that's that's a really good question
Dialogue: 0,0:27:12.06,0:27:13.70,csapp,,0,0,0,,so there's a lot of different algorithms
Dialogue: 0,0:27:14.32,0:27:19.48,csapp,,0,0,0,, the most the most common algorithm or a common algorithm is least recently used
Dialogue: 0,0:27:20.26,0:27:26.32,csapp,,0,0,0,,so by locality you you want to keep the you want to keep blocks in the cache that are being used a lot
Dialogue: 0,0:27:27.32,0:27:31.84,csapp,,0,0,0,,and so if a block isn't referenced for a long time by the principle of locality
Dialogue: 0,0:27:32.20,0:27:34.94,csapp,,0,0,0,,by sort of the inverse locality principle
Dialogue: 0,0:27:35.40,0:27:39.32,csapp,,0,0,0,, it's it's likely not to be addressed referenced in the near future
Dialogue: 0,0:27:40.00,0:27:42.92,csapp,,0,0,0,, so so that's one that's one algorithm
Dialogue: 0,0:27:42.96,0:27:48.60,csapp,,0,0,0,,that you just keep track of and and I'm not showing there needs to be additional bits
Dialogue: 0,0:27:49.06,0:27:53.44,csapp,,0,0,0,,in the line to sort of keep like sort of virtual timestamps that
Dialogue: 0,0:27:54.28,0:27:56.92,csapp,,0,0,0,, but that's that's a that's sort of the general way you do it
Dialogue: 0,0:27:56.92,0:28:04.78,csapp,,0,0,0,,just try to keep the things that are the blocks that are being accessed the most frequently  most recently yes
Dialogue: 0,0:28:08.96,0:28:11.74,csapp,,0,0,0,,okay the question is what determines the block size
Dialogue: 0,0:28:12.92,0:28:15.28,csapp,,0,0,0,,that's determined by the design of the memory system
Dialogue: 0,0:28:15.98,0:28:20.86,csapp,,0,0,0,,so that's a that's that's a fixed parameter of the memory system
Dialogue: 0,0:28:21.38,0:28:26.50,csapp,,0,0,0,,so when the Intel designers decided to put cache memories on their processors
Dialogue: 0,0:28:27.18,0:28:30.20,csapp,,0,0,0,, they decided that the block size would be 64 bytes
Dialogue: 0,0:28:33.30,0:28:37.28,csapp,,0,0,0,,sorry
Dialogue: 0,0:28:39.28,0:28:43.68,csapp,,0,0,0,,so the block size comes the block size comes first
Dialogue: 0,0:28:44.76,0:28:48.46,csapp,,0,0,0,,then then you determine how big you want your cache to be
Dialogue: 0,0:28:49.66,0:28:52.78,csapp,,0,0,0,,okay and then and you determine the associativity
Dialogue: 0,0:28:54.54,0:28:59.08,csapp,,0,0,0,,okay and then once you've determined the associativity and you know how big your cache is
Dialogue: 0,0:28:59.54,0:29:01.32,csapp,,0,0,0,, then that determines the number of sets
Dialogue: 0,0:29:02.68,0:29:09.23,csapp,,0,0,0,,okay so basically all of those the
Dialogue: 0,0:29:09.70,0:29:16.62,csapp,,0,0,0,,the the number of lines and the cat and the capacity
Dialogue: 0,0:29:16.72,0:29:21.70,csapp,,0,0,0,,the number of lines per set is sort of a fixed high-level parameter design parameter
Dialogue: 0,0:29:21.98,0:29:26.50,csapp,,0,0,0,, the size of the cache is a is a is a high-level design parameter
Dialogue: 0,0:29:26.84,0:29:29.88,csapp,,0,0,0,,and then the number of sets then is induced from the from that
Dialogue: 0,0:29:30.65,0:29:40.74,csapp,,0,0,0,,okay yes
Dialogue: 0,0:29:41.06,0:29:45.38,csapp,,0,0,0,,ah that that's yeah how does so that's that's the replacement policy
Dialogue: 0,0:29:46.28,0:29:51.74,csapp,,0,0,0,,how does it so the question is how does it when there's multiple lines in a set how does it determine which to over overwrite
Dialogue: 0,0:29:52.32,0:29:55.88,csapp,,0,0,0,,and that was what that was the previous question probably maybe I should have repeated it
Dialogue: 0,0:29:56.34,0:30:00.14,csapp,,0,0,0,,so you try to pick a line that that was least recently used
Dialogue: 0,0:30:00.90,0:30:03.42,csapp,,0,0,0,,so lines lines that haven't been accessed
Dialogue: 0,0:30:04.36,0:30:06.98,csapp,,0,0,0,,recently are good candidates for replacement because
Dialogue: 0,0:30:07.14,0:30:09.90,csapp,,0,0,0,, because of the sort of inverse locality principle right that
Dialogue: 0,0:30:10.18,0:30:14.58,csapp,,0,0,0,, they haven't been inverse referenced recently chances are they won't be referenced
Dialogue: 0,0:30:15.16,0:30:19.06,csapp,,0,0,0,,again it
Dialogue: 0,0:30:19.08,0:30:22.28,csapp,,0,0,0,,oh yeah there's additional bits that I'm not showing here that you have to
Dialogue: 0,0:30:22.82,0:30:25.58,csapp,,0,0,0,, so so when you replace a line in the set
Dialogue: 0,0:30:26.16,0:30:30.56,csapp,,0,0,0,, if that data is has changed then it has to be written back to memory
Dialogue: 0,0:30:30.58,0:30:31.94,csapp,,0,0,0,,and that's another bit I haven't shown
Dialogue: 0,0:30:31.94,0:30:44.46,csapp,,0,0,0,,yes
Dialogue: 0,0:30:44.46,0:30:52.14,csapp,,0,0,0,,ah so the so yeah so this is a really this is really tricky  parameter writing
Dialogue: 0,0:30:52.14,0:30:56.72,csapp,,0,0,0,,it's it's a it's a high level system parameter that's that it goes on for years
Dialogue: 0,0:30:57.62,0:31:02.02,csapp,,0,0,0,,so the idea you want to have blocks in order to exploit spatial locality
Dialogue: 0,0:31:03.10,0:31:07.20,csapp,,0,0,0,,right think about if you're going to go to the trouble of if you have a miss in cash
Dialogue: 0,0:31:07.68,0:31:11.94,csapp,,0,0,0,,and you're going to go to the trouble of going all the way to memory to get some data
Dialogue: 0,0:31:12.64,0:31:18.94,csapp,,0,0,0,,you want to you want to amortize the cost of fetching that data by fetching more than one byte
Dialogue: 0,0:31:19.78,0:31:21.66,csapp,,0,0,0,, that that's the motivation for blocks
Dialogue: 0,0:31:22.46,0:31:29.34,csapp,,0,0,0,,because by by the by the principle of locality in spatial locality in particular
Dialogue: 0,0:31:30.64,0:31:32.90,csapp,,0,0,0,,if you reference a word inside of a block
Dialogue: 0,0:31:32.90,0:31:36.60,csapp,,0,0,0,,chances are you're going to reference a nearby word which will also be an epilogue
Dialogue: 0,0:31:37.52,0:31:42.98,csapp,,0,0,0,,okay so blocks the whole purpose of blocks is to exploit spatial locality
Dialogue: 0,0:31:43.40,0:31:49.28,csapp,,0,0,0,,now if you make your block too small then you don't you don't amortize
Dialogue: 0,0:31:49.66,0:31:54.00,csapp,,0,0,0,,you don't get the same amortization right you maybe get one you bring the block in
Dialogue: 0,0:31:55.10,0:31:57.62,csapp,,0,0,0,,so there's a reference you get a miss you bring the block in
Dialogue: 0,0:31:58.12,0:32:01.60,csapp,,0,0,0,,there's another reference nearby you get a hit because the blocks in memory
Dialogue: 0,0:32:02.24,0:32:04.76,csapp,,0,0,0,,but then the next reference is in a different block
Dialogue: 0,0:32:05.32,0:32:06.90,csapp,,0,0,0,, because your block sizes are too small
Dialogue: 0,0:32:07.22,0:32:11.68,csapp,,0,0,0,,right so you kind of want to make blocks big as big as possible
Dialogue: 0,0:32:12.10,0:32:13.74,csapp,,0,0,0,,but without slowing the system down
Dialogue: 0,0:32:13.74,0:32:17.84,csapp,,0,0,0,,so if you made your block size too big it would just take too long to bring that block in
Dialogue: 0,0:32:19.06,0:32:26.10,csapp,,0,0,0,,plus plus now your blocks that your blocks are taking up bits in your cache memory
Dialogue: 0,0:32:26.48,0:32:28.12,csapp,,0,0,0,,so now there's no room for other blocks
Dialogue: 0,0:32:28.12,0:32:32.12,csapp,,0,0,0,,right so it's a really it's a really tricky design problem right and
Dialogue: 0,0:32:32.60,0:32:37.54,csapp,,0,0,0,,if we're doing it taking an architecture class then we would we would sort of dive into the
Dialogue: 0,0:32:38.12,0:32:41.46,csapp,,0,0,0,,you know how how architects make those design decisions
Dialogue: 0,0:32:41.86,0:32:44.72,csapp,,0,0,0,,but in general that's what it's kind of a balancing act right
Dialogue: 0,0:32:46.30,0:32:56.02,csapp,,0,0,0,,were there any other questions yes
Dialogue: 0,0:32:56.18,0:32:58.72,csapp,,0,0,0,,Oh the question is every time there's a miss
Dialogue: 0,0:32:58.72,0:33:02.34,csapp,,0,0,0,,do you have to do you have to select a victim line and override it
Dialogue: 0,0:33:03.00,0:33:07.32,csapp,,0,0,0,,yeah I don't know of any caches that that don't do that
Dialogue: 0,0:33:07.92,0:33:09.48,csapp,,0,0,0,,now we'll see when we look at rights
Dialogue: 0,0:33:10.70,0:33:14.88,csapp,,0,0,0,,we'll see there's an option of whether we're only looking at reads right now
Dialogue: 0,0:33:15.16,0:33:17.02,csapp,,0,0,0,,but with rights that question does come up
Dialogue: 0,0:33:17.86,0:33:24.02,csapp,,0,0,0,,okay and if if you wait and in a couple of slides we'll go over we'll go over that
Dialogue: 0,0:33:24.78,0:33:25.80,csapp,,0,0,0,,any other questions
Dialogue: 0,0:33:29.04,0:33:32.48,csapp,,0,0,0,,okay so let's look at this this two-way associative cache  now
Dialogue: 0,0:33:33.94,0:33:36.78,csapp,,0,0,0,,there's there's one block offset bit
Dialogue: 0,0:33:37.30,0:33:40.18,csapp,,0,0,0,,we only have two sets so that we only need one set index
Dialogue: 0,0:33:41.04,0:33:42.96,csapp,,0,0,0,,and then the remaining two bits are tagged
Dialogue: 0,0:33:44.02,0:33:50.14,csapp,,0,0,0,,so let's go through our trace so address zero has a set is in set zero right here
Dialogue: 0,0:33:51.58,0:33:54.54,csapp,,0,0,0,, that's a Miss so we load that into memory
Dialogue: 0,0:33:59.72,0:34:01.50,csapp,,0,0,0,,with the reference to address one
Dialogue: 0,0:34:02.24,0:34:08.10,csapp,,0,0,0,, that's in set zero and that's a hit because that that byte is in is in our block
Dialogue: 0,0:34:09.08,0:34:13.04,csapp,,0,0,0,,the reference to seven is a Miss that's in set one so we load that
Dialogue: 0,0:34:13.56,0:34:17.36,csapp,,0,0,0,,and we were just picking randomly pick one of these two over right
Dialogue: 0,0:34:18.54,0:34:20.80,csapp,,0,0,0,,because they're there the cache is empty
Dialogue: 0,0:34:21.34,0:34:25.72,csapp,,0,0,0,,the next reference is to address number eight which is in set zero
Dialogue: 0,0:34:26.20,0:34:31.80,csapp,,0,0,0,,now here's here's the difference between the direct mapped cache and this 2-way set-associative cache
Dialogue: 0,0:34:32.86,0:34:35.66,csapp,,0,0,0,, when we when we reference address eight
Dialogue: 0,0:34:36.90,0:34:42.26,csapp,,0,0,0,, that block has to the corresponding block has to go into set 0
Dialogue: 0,0:34:42.98,0:34:44.74,csapp,,0,0,0,,because of this zero set index bit
Dialogue: 0,0:34:45.46,0:34:49.38,csapp,,0,0,0,, but we've got room now because we are set to have room for two lines instead of one
Dialogue: 0,0:34:50.52,0:34:55.18,csapp,,0,0,0,,so when we load that in well if we have an available empty slot
Dialogue: 0,0:34:55.18,0:35:01.02,csapp,,0,0,0,,we'll put it there we won't overwrite anything right so if possible always try to overwrite  empty empty lines
Dialogue: 0,0:35:02.64,0:35:07.86,csapp,,0,0,0,,so now we've got in this set we've got block 0 1 and block 8 9
Dialogue: 0,0:35:08.38,0:35:12.46,csapp,,0,0,0,,so when we get our reference to block to address zero
Dialogue: 0,0:35:13.04,0:35:16.94,csapp,,0,0,0,, whereas before with the when we had a conflict miss in the direct map cache
Dialogue: 0,0:35:16.94,0:35:19.94,csapp,,0,0,0,,now we can we can satisfy that that request
Dialogue: 0,0:35:20.60,0:35:25.28,csapp,,0,0,0,,it hits in memory and week and the cache can satisfy it from  from the cache instead of going to memory
Dialogue: 0,0:35:26.78,0:35:30.40,csapp,,0,0,0,, okay so that makes sense
Dialogue: 0,0:35:35.38,0:35:36.68,csapp,,0,0,0,,okay now what about rights
Dialogue: 0,0:35:39.20,0:35:41.38,csapp,,0,0,0,,so there's multiple copies of the data
Dialogue: 0,0:35:42.08,0:35:49.96,csapp,,0,0,0,,right we're sub setting as we move up the hierarchy we're creating subsets of the data  in the caches
Dialogue: 0,0:35:50.88,0:36:00.62,csapp,,0,0,0,,so what do we do if we do a write to a word within a block that's currently in the cache
Dialogue: 0,0:36:02.86,0:36:04.82,csapp,,0,0,0,,okay we have we have two options
Dialogue: 0,0:36:05.46,0:36:09.02,csapp,,0,0,0,,we can write that block immediately to memory right
Dialogue: 0,0:36:09.68,0:36:13.26,csapp,,0,0,0,,we're we've got a block that's like this big and we're updating a little chunk of it
Dialogue: 0,0:36:15.10,0:36:19.66,csapp,,0,0,0,,so we can we can either do the update and then flush it to memory immediately so that
Dialogue: 0,0:36:20.50,0:36:25.02,csapp,,0,0,0,,memory always mirrors the contents of memory always mirror the contents of the cache
Dialogue: 0,0:36:26.42,0:36:29.60,csapp,,0,0,0,,okay but that's expensive right
Dialogue: 0,0:36:29.62,0:36:32.44,csapp,,0,0,0,, I mean you know memory accesses are expensive
Dialogue: 0,0:36:33.68,0:36:36.96,csapp,,0,0,0,,the other so the other option is what what's called write back
Dialogue: 0,0:36:37.90,0:36:40.56,csapp,,0,0,0,,so in this case when we write to a block in the cache
Dialogue: 0,0:36:41.66,0:36:44.80,csapp,,0,0,0,,we don't we don't flush it to memory
Dialogue: 0,0:36:45.14,0:36:50.94,csapp,,0,0,0,,until we elect that particular line as a victim that's going to be overwritten
Dialogue: 0,0:36:52.38,0:36:55.90,csapp,,0,0,0,,and only then only then when we're just we sort of defer
Dialogue: 0,0:36:55.92,0:36:58.56,csapp,,0,0,0,,the writing to memory until the last possible minute
Dialogue: 0,0:36:59.22,0:37:04.71,csapp,,0,0,0,,we defer it until just before the cache would overwrite that  that data block
Dialogue: 0,0:37:05.36,0:37:06.80,csapp,,0,0,0,,okay so that's called right back
Dialogue: 0,0:37:07.20,0:37:12.90,csapp,,0,0,0,,and for right back you need to have some an extra bit in the line that indicates whether that that blocks been written to
Dialogue: 0,0:37:13.60,0:37:18.88,csapp,,0,0,0,,so the algorithm is when when the cache identifies a particular line to overwrite
Dialogue: 0,0:37:19.62,0:37:25.50,csapp,,0,0,0,,it checks the dirty bit on that fine if it's set then it writes that data to back to disk
Dialogue: 0,0:37:28.18,0:37:33.26,csapp,,0,0,0,,okay if the data hasn't if that block hasn't been written there's no point there's no need to write it back
Dialogue: 0,0:37:33.26,0:37:38.14,csapp,,0,0,0,, because it's the same it has the same value as the copy of the block on disk
Dialogue: 0,0:37:41.20,0:37:45.74,csapp,,0,0,0,,okay now so what about so that's a right here now what happens if we have a right miss
Dialogue: 0,0:37:46.46,0:37:48.98,csapp,,0,0,0,,so we're doing a write to memory
Dialogue: 0,0:37:50.60,0:37:55.88,csapp,,0,0,0,, and the word that we're writing is is not contained in any block that's in our cache
Dialogue: 0,0:37:57.90,0:38:02.58,csapp,,0,0,0,,so we have two options we can do what's called write allocate so we can treat it if if there's a Miss
Dialogue: 0,0:38:03.24,0:38:07.32,csapp,,0,0,0,,we can do sort of the symmetric thing that we did with it with a hit which was create a new
Dialogue: 0,0:38:08.08,0:38:11.26,csapp,,0,0,0,, a newline possibly overwriting an existing line
Dialogue: 0,0:38:11.96,0:38:18.18,csapp,,0,0,0,,and then write in so we could so we could create that cache enter that cache line
Dialogue: 0,0:38:18.48,0:38:21.48,csapp,,0,0,0,, fetch it from memory and then do and then do the do the right
Dialogue: 0,0:38:23.18,0:38:25.34,csapp,,0,0,0,, okay so this is sort of symmetric to reads right then
Dialogue: 0,0:38:25.80,0:38:32.10,csapp,,0,0,0,,so every right if it misses when the write finishes the that block will be in the cache
Dialogue: 0,0:38:33.10,0:38:35.56,csapp,,0,0,0,,and if we do a subsequent read we get a hit
Dialogue: 0,0:38:36.04,0:38:38.18,csapp,,0,0,0,,okay so that's the reason you might want to do that
Dialogue: 0,0:38:40.56,0:38:42.92,csapp,,0,0,0,,the the other option is just to
Dialogue: 0,0:38:43.44,0:38:50.18,csapp,,0,0,0,,don't allocate a an entry in the cache don't allocate a new line just write write the data directly to memory
Dialogue: 0,0:38:52.48,0:38:56.00,csapp,,0,0,0,,you don't really need to understand the distinction between these two things
Dialogue: 0,0:38:56.44,0:38:58.66,csapp,,0,0,0,,different caches use different policies
Dialogue: 0,0:38:59.27,0:39:06.18,csapp,,0,0,0,,for your own mental model a good model to use is just to assume write back write allocate
Dialogue: 0,0:39:07.08,0:39:10.22,csapp,,0,0,0,, so just assume that we won't we won't copy the data to disk
Dialogue: 0,0:39:10.76,0:39:14.84,csapp,,0,0,0,, if there's a hit we won't write it back to disk until the last possible minute
Dialogue: 0,0:39:15.28,0:39:19.72,csapp,,0,0,0,,and every time there's a write miss what will create a new entry in the cache
Dialogue: 0,0:39:20.28,0:39:23.84,csapp,,0,0,0,,okay so that's that I think that's sort of the simplest model that
Dialogue: 0,0:39:24.32,0:39:30.84,csapp,,0,0,0,,and it's a reason it's a reasonable model that you can use regardless  of the particular cache implementation
Dialogue: 0,0:39:33.78,0:39:38.04,csapp,,0,0,0,,now in a real system so far we've only looked at we've only assumed that there's a single cache
Dialogue: 0,0:39:38.52,0:39:44.86,csapp,,0,0,0,,but in a in real systems there's multiple multiple caches
Dialogue: 0,0:39:46.66,0:39:53.86,csapp,,0,0,0,,so modern core i7 Haswell architecture from Intel
Dialogue: 0,0:39:56.24,0:39:58.48,csapp,,0,0,0,,contains multiple processor cores
Dialogue: 0,0:39:59.40,0:40:02.32,csapp,,0,0,0,,so 4 is a typical number for like desktop systems
Dialogue: 0,0:40:02.80,0:40:06.12,csapp,,0,0,0,,8 8 to 12 is typical for server class systems
Dialogue: 0,0:40:06.74,0:40:12.58,csapp,,0,0,0,,these processor cores can each execute their own independent instruction stream in parallel
Dialogue: 0,0:40:14.54,0:40:21.34,csapp,,0,0,0,,and each processor core can contains general-purpose registers which that's level 0 in the cache
Dialogue: 0,0:40:22.46,0:40:26.30,csapp,,0,0,0,,and then two different kinds of l1 caches
Dialogue: 0,0:40:27.20,0:40:29.16,csapp,,0,0,0,, the data cache the l1d cache
Dialogue: 0,0:40:30.26,0:40:33.86,csapp,,0,0,0,,and the eye cache is the L which is the instruction cache
Dialogue: 0,0:40:35.28,0:40:40.16,csapp,,0,0,0,,and these are these are fairly small 32 K bytes they're eight-way associative
Dialogue: 0,0:40:40.74,0:40:44.14,csapp,,0,0,0,,and they can be accessed in a very small number of cycles
Dialogue: 0,0:40:45.60,0:40:51.40,csapp,,0,0,0,, the next level of the hierarchy is is the L is an l2 cache
Dialogue: 0,0:40:52.12,0:40:58.58,csapp,,0,0,0,,which is still fairly small 256 K bytes same associativity
Dialogue: 0,0:40:59.12,0:41:02.30,csapp,,0,0,0,,and it has a slightly longer access time
Dialogue: 0,0:41:03.14,0:41:08.68,csapp,,0,0,0,,and and it's unified in the sense that the l2 cache contains both data and instructions
Dialogue: 0,0:41:11.42,0:41:14.10,csapp,,0,0,0,,ok so that's all within a single core on the chip
Dialogue: 0,0:41:15.74,0:41:20.80,csapp,,0,0,0,,and then also on the chip but external to all the cores and shared by all the cores
Dialogue: 0,0:41:21.36,0:41:27.62,csapp,,0,0,0,, is at l3 unified cache which is 8 megabytes and 16 Way associative
Dialogue: 0,0:41:28.06,0:41:31.74,csapp,,0,0,0,,with an access time that's like 40 to 75 cycles
Dialogue: 0,0:41:33.84,0:41:43.06,csapp,,0,0,0,,so if if there's a Miss in l1 then the l1 sense or tries to sends a request to l2 to try to try to find the data in l2
Dialogue: 0,0:41:43.08,0:41:47.60,csapp,,0,0,0,,since l2 is a little bigger maybe maybe the data hasn't been flushed out of l2 yet
Dialogue: 0,0:41:48.14,0:41:55.10,csapp,,0,0,0,,if l2 can't find it it sends a request to l3 to see if they can find the data in l3
Dialogue: 0,0:41:55.88,0:41:59.62,csapp,,0,0,0,,if l3 can't find it then it gives up and it goes off chip to to memory
Dialogue: 0,0:42:00.46,0:42:03.88,csapp,,0,0,0,,yes question
Dialogue: 0,0:42:03.92,0:42:09.32,csapp,,0,0,0,,yes name memory is this that's it's the DRAM built of DRAM chips
Dialogue: 0,0:42:09.94,0:42:13.96,csapp,,0,0,0,,it's it's separate it's in a separate separate set of chips on the motherboard
Dialogue: 0,0:42:14.90,0:42:18.22,csapp,,0,0,0,,connected by those that IO bridge
Dialogue: 0,0:42:18.22,0:42:22.90,csapp,,0,0,0,, that we and the bus various buses then that we talked about last time
Dialogue: 0,0:42:29.14,0:42:34.02,csapp,,0,0,0,,and for all different for all of these different caches that block size is 64 bytes
Dialogue: 0,0:42:38.88,0:42:44.60,csapp,,0,0,0,,now there's a number of different ways to I think about the performance of caches
Dialogue: 0,0:42:46.72,0:42:51.36,csapp,,0,0,0,, my most most common way is using a metric called the Miss rate
Dialogue: 0,0:42:52.08,0:42:54.96,csapp,,0,0,0,,so what this is the fraction of references that Miss
Dialogue: 0,0:42:56.50,0:43:00.34,csapp,,0,0,0,,so we're very so I thought and it's it's 1 minus the hit rate
Dialogue: 0,0:43:01.56,0:43:06.22,csapp,,0,0,0,,so typical for caches to work that Miss rate has to be pretty low
Dialogue: 0,0:43:07.58,0:43:11.70,csapp,,0,0,0,,and and fortunately because of locality these miss rates are low
Dialogue: 0,0:43:13.38,0:43:16.66,csapp,,0,0,0,,another another metric is the hit time
Dialogue: 0,0:43:16.66,0:43:22.94,csapp,,0,0,0,, so if if we do have a hit in the cache how long does it actually take to sort of look up the
Dialogue: 0,0:43:23.22,0:43:26.78,csapp,,0,0,0,,you know do the lookup to determine that there was a hit and then return the value
Dialogue: 0,0:43:29.08,0:43:36.66,csapp,,0,0,0,, okay so for for l1 and in an Intel system this is four clock cycles  ten clock cycles for l2
Dialogue: 0,0:43:37.74,0:43:39.40,csapp,,0,0,0,,and then there's an additional cost if
Dialogue: 0,0:43:39.92,0:43:43.62,csapp,,0,0,0,, so you always have to pay the hit time right the hit time is the best you can do
Dialogue: 0,0:43:45.42,0:43:49.08,csapp,,0,0,0,,but if you have a Miss then it's you pay the hit time
Dialogue: 0,0:43:50.66,0:43:54.80,csapp,,0,0,0,,because you have to do the search and eventually you're going to have to return the word back to the requester
Dialogue: 0,0:43:55.32,0:43:57.34,csapp,,0,0,0,,but you then you have this additional cost
Dialogue: 0,0:43:57.34,0:44:01.24,csapp,,0,0,0,,which you have to go which is going to the the memory ready to fetch the data
Dialogue: 0,0:44:02.16,0:44:05.76,csapp,,0,0,0,,okay so that that Miss penalty that's what called miss penalty
Dialogue: 0,0:44:07.40,0:44:10.16,csapp,,0,0,0,,is on the order of hundreds of cycles for main memory
Dialogue: 0,0:44:11.00,0:44:14.35,csapp,,0,0,0,,but at other levels of the hierarchy it can be huge
Dialogue: 0,0:44:14.84,0:44:18.02,csapp,,0,0,0,,so the miss penalty if you if you have a cache in main memory
Dialogue: 0,0:44:18.64,0:44:23.12,csapp,,0,0,0,,that's caching blocks that are stored on disk the the Miss penalty is enormous
Dialogue: 0,0:44:28.60,0:44:32.00,csapp,,0,0,0,,so it's kind of interesting if you think about it
Dialogue: 0,0:44:34.00,0:44:39.74,csapp,,0,0,0,,that performance is the performance of these systems is very sensitive to the miss rate much more sensitive than you would think
Dialogue: 0,0:44:41.32,0:44:49.66,csapp,,0,0,0,,and in fact 99% hit rate is twice as good as a 97 percent hit rate
Dialogue: 0,0:44:50.54,0:45:06.74,csapp,,0,0,0,,yes
Dialogue: 0,0:45:06.86,0:45:13.50,csapp,,0,0,0,,yeah they hit so the question is does the hit time include the time tax to access the tag and yes
Dialogue: 0,0:45:13.80,0:45:17.38,csapp,,0,0,0,,so the hit time is the time it takes to just to search
Dialogue: 0,0:45:17.96,0:45:22.16,csapp,,0,0,0,,to determine if that item is is is in the cache and then return it
Dialogue: 0,0:45:22.16,0:45:39.20,csapp,,0,0,0,,[student speaking]
Dialogue: 0,0:45:39.22,0:45:48.20,csapp,,0,0,0,,yeah so the yeah so the the miss the Miss penalty is the time it takes for the cash to fetch the data from memory
Dialogue: 0,0:45:48.94,0:45:51.92,csapp,,0,0,0,,so that's all the latency you know going across the buses
Dialogue: 0,0:45:52.28,0:45:55.32,csapp,,0,0,0,,the time it takes the memory to respond to the requests
Dialogue: 0,0:45:55.83,0:45:59.78,csapp,,0,0,0,,the time it takes the data to flow back over the buses back to the the cache
Dialogue: 0,0:46:00.48,0:46:05.10,csapp,,0,0,0,,so the time for a Miss is going to be the hit time plus the Miss penalty  that clear
Dialogue: 0,0:46:09.76,0:46:17.00,csapp,,0,0,0,, so I mean imagine suppose there's a hit time of one cycle and a Miss penalty of 100 cycles that those are reasonable numbers
Dialogue: 0,0:46:18.48,0:46:22.76,csapp,,0,0,0,,so the the average acts I asked access time if you have 97 percent hits
Dialogue: 0,0:46:24.22,0:46:29.48,csapp,,0,0,0,,it's the hit time plus the percentage of misses times the Miss penalty
Dialogue: 0,0:46:30.06,0:46:32.66,csapp,,0,0,0,,so that's four cycles for the average access time
Dialogue: 0,0:46:33.36,0:46:36.56,csapp,,0,0,0,,but if we just increase the the hit rate by two percent
Dialogue: 0,0:46:37.38,0:46:42.72,csapp,,0,0,0,,the average access time drops by fifty percent  a factor of two
Dialogue: 0,0:46:47.26,0:46:51.72,csapp,,0,0,0,,all right so why why is this stuff important why why should you care about it
Dialogue: 0,0:46:53.42,0:46:57.78,csapp,,0,0,0,,so cash is that we as we've seen are these these they're automatic they're all built in hardware
Dialogue: 0,0:46:58.44,0:47:04.48,csapp,,0,0,0,, there's no part of the sort of the visible instruction set that
Dialogue: 0,0:47:05.02,0:47:09.94,csapp,,0,0,0,,lets you manipulate caches and your assembly machine codons programs
Dialogue: 0,0:47:11.72,0:47:16.32,csapp,,0,0,0,, so that it all happens behind the scenes automatically in hardware
Dialogue: 0,0:47:17.42,0:47:21.26,csapp,,0,0,0,,but if you know how kit if you know about the existence of caches
Dialogue: 0,0:47:21.26,0:47:24.18,csapp,,0,0,0,,and you have this general idea of how you can work how they work
Dialogue: 0,0:47:24.84,0:47:27.76,csapp,,0,0,0,,then you can write code that's cache friendly
Dialogue: 0,0:47:27.76,0:47:36.68,csapp,,0,0,0,,in the sense that your code will have a higher higher miss rate than code that that isn't cache friendly
Dialogue: 0,0:47:37.96,0:47:44.76,csapp,,0,0,0,,so the idea is to you want to focus on making the common case go fast
Dialogue: 0,0:47:44.82,0:47:48.90,csapp,,0,0,0,,don't spend your time on code  that sort of code that doesn't get execute very much
Dialogue: 0,0:47:50.16,0:47:53.00,csapp,,0,0,0,,much so look at look at the most commonly called functions
Dialogue: 0,0:47:54.32,0:47:57.12,csapp,,0,0,0,, and then within those functions look at the inner loops of those functions
Dialogue: 0,0:47:57.12,0:47:59.36,csapp,,0,0,0,,because it's the inner loops that are executing the most
Dialogue: 0,0:48:00.30,0:48:04.78,csapp,,0,0,0,, right so you can as a first approximation you can just ignore sort of stuff
Dialogue: 0,0:48:04.78,0:48:08.76,csapp,,0,0,0,, if you have nested loops you can ignore stuff that's going on in the outer loops
Dialogue: 0,0:48:08.78,0:48:11.02,csapp,,0,0,0,,and just focus on the code in the inner loop
Dialogue: 0,0:48:12.36,0:48:15.22,csapp,,0,0,0,,now what you want to do is try to minimize the misses in the inner loop
Dialogue: 0,0:48:16.62,0:48:21.91,csapp,,0,0,0,,okay so repeated references to a variable is variables are good
Dialogue: 0,0:48:22.34,0:48:24.20,csapp,,0,0,0,,especially if those are local variables
Dialogue: 0,0:48:24.78,0:48:27.56,csapp,,0,0,0,,right so remember if you declare a local variable and see
Dialogue: 0,0:48:28.52,0:48:30.90,csapp,,0,0,0,, the compiler can put that in a register
Dialogue: 0,0:48:32.30,0:48:34.30,csapp,,0,0,0,, right if you're referencing global variables
Dialogue: 0,0:48:34.72,0:48:37.26,csapp,,0,0,0,,maybe not the compiler doesn't know what's going on
Dialogue: 0,0:48:37.72,0:48:44.30,csapp,,0,0,0,,so it can't put that ref it can't put the reference to that variable to see in a register
Dialogue: 0,0:48:44.98,0:48:50.18,csapp,,0,0,0,,okay so repeated references to local variables stored on the stack are good
Dialogue: 0,0:48:50.48,0:48:52.78,csapp,,0,0,0,,because those will get turned into register accesses
Dialogue: 0,0:48:53.06,0:48:54.30,csapp,,0,0,0,, you'll never go to memory
Dialogue: 0,0:48:55.42,0:48:58.90,csapp,,0,0,0,,okay also stride one accesses two arrays are good
Dialogue: 0,0:48:59.98,0:49:02.60,csapp,,0,0,0,,and they're good because of the existence of these blocks
Dialogue: 0,0:49:03.20,0:49:07.48,csapp,,0,0,0,, right so the only way you'd know that stride one references our good is if you knew that
Dialogue: 0,0:49:07.90,0:49:10.20,csapp,,0,0,0,,caches have the 64-byte blocks
Dialogue: 0,0:49:11.88,0:49:18.34,csapp,,0,0,0,,okay so the and stride one one reference will have half the Miss rate as a stride to reference
Dialogue: 0,0:49:19.74,0:49:26.42,csapp,,0,0,0,, because if you're doing stride one references the first reference to a word and a block will miss
Dialogue: 0,0:49:27.70,0:49:29.68,csapp,,0,0,0,, but then subsequent references will hit
Dialogue: 0,0:49:31.64,0:49:37.42,csapp,,0,0,0,, right and you'll hit if you're doing a stride one reference you're going to hit every every word in that block
Dialogue: 0,0:49:38.10,0:49:41.84,csapp,,0,0,0,,  if your drive if you're doing stride two references you're only going to hit every other word
Dialogue: 0,0:49:42.78,0:49:46.92,csapp,,0,0,0,,right so you'll only get you'll get sort of half the so you'll missed at twice the rate
Dialogue: 0,0:49:50.98,0:49:51.92,csapp,,0,0,0,,so
Dialogue: 0,0:49:54.38,0:49:59.28,csapp,,0,0,0,,so basically the point I want to make to you is that our understanding of caches
Dialogue: 0,0:49:59.84,0:50:06.20,csapp,,0,0,0,,allow us to sort of quantify this this qualitative notion of locality that we developed the last time
Dialogue: 0,0:50:06.20,0:50:11.06,csapp,,0,0,0,, right the last time we looked at we said if it's doing stride one references that's good if
Dialogue: 0,0:50:11.64,0:50:16.98,csapp,,0,0,0,,it's if we're doing if we're accessing the same variable over and over that's good
Dialogue: 0,0:50:17.62,0:50:21.74,csapp,,0,0,0,,but if we understand caches now we can quantify it in terms of miss rate
Dialogue: 0,0:50:26.42,0:50:28.82,csapp,,0,0,0,,all right so let's finish up the rest of the class
Dialogue: 0,0:50:28.82,0:50:32.50,csapp,,0,0,0,,we're going to look at the performance impact of caches on your code
Dialogue: 0,0:50:33.00,0:50:36.43,csapp,,0,0,0,,okay and why why you need to why you need to know about these things
Dialogue: 0,0:50:37.16,0:50:39.10,csapp,,0,0,0,,and that the impact that they can have
Dialogue: 0,0:50:41.52,0:50:44.58,csapp,,0,0,0,, so there's a very interesting function
Dialogue: 0,0:50:45.22,0:50:48.32,csapp,,0,0,0,,this actually plotted on the cover of your your text book
Dialogue: 0,0:50:49.12,0:50:50.50,csapp,,0,0,0,,that we call the memory Mountain
Dialogue: 0,0:50:51.10,0:50:59.14,csapp,,0,0,0,,I learned about this from a graduate student here at Carnegie Mellon back in the 90s who developed this notion made Tom Stricker
Dialogue: 0,0:51:00.34,0:51:07.66,csapp,,0,0,0,,and what it is it's a the memory Mountain plots a measure called read through put or read bandwidth
Dialogue: 0,0:51:08.18,0:51:10.38,csapp,,0,0,0,,which is the number of bytes read from memory
Dialogue: 0,0:51:10.66,0:51:16.08,csapp,,0,0,0,,so if you have four if you have a loop and you're scanning over a vector
Dialogue: 0,0:51:16.36,0:51:19.40,csapp,,0,0,0,,so you have a vector of say say double words
Dialogue: 0,0:51:20.20,0:51:23.86,csapp,,0,0,0,,and you're reading those elements from a vector one after the other
Dialogue: 0,0:51:24.68,0:51:30.04,csapp,,0,0,0,,the read throughput is the number of megabytes per second that you can that you can perform that task
Dialogue: 0,0:51:31.14,0:51:34.62,csapp,,0,0,0,,at and the memory Mountain plots read throughput
Dialogue: 0,0:51:35.02,0:51:39.48,csapp,,0,0,0,,as a function of the temporal and spatial locality in that loop
Dialogue: 0,0:51:41.20,0:51:48.60,csapp,,0,0,0,,okay so in a sense it's looking at a wide range of locality options  or characteristics in a program
Dialogue: 0,0:51:48.80,0:51:55.68,csapp,,0,0,0,,and it's plotting the performance of that memory system on that across that range as a two-dimensional function
Dialogue: 0,0:51:56.08,0:51:58.23,csapp,,0,0,0,,so in some ways the memory Mountain is a
Dialogue: 0,0:51:59.10,0:52:02.56,csapp,,0,0,0,,kind of a fingerprint right every system has its own unique memory Mountain
Dialogue: 0,0:52:03.26,0:52:06.04,csapp,,0,0,0,,that we can measure right by writing a simple program
Dialogue: 0,0:52:07.50,0:52:14.22,csapp,,0,0,0,,and so the idea here is that to construct the memory Mountain
Dialogue: 0,0:52:15.08,0:52:16.78,csapp,,0,0,0,,we write a program called test
Dialogue: 0,0:52:35.50,0:52:36.60,csapp,,0,0,0,,oh shoot
Dialogue: 0,0:52:51.54,0:52:53.04,csapp,,0,0,0,,for some reason it's not
Dialogue: 0,0:52:57.02,0:53:01.56,csapp,,0,0,0,,okay  right
Dialogue: 0,0:53:04.22,0:53:06.66,csapp,,0,0,0,,so when we when we when we build a memory Mountain
Dialogue: 0,0:53:07.38,0:53:12.66,csapp,,0,0,0,, we're given a vector that consists of a collection of double words
Dialogue: 0,0:53:17.60,0:53:24.40,csapp,,0,0,0,,and then we write a loop that reads those words that read some number of words in this case
Dialogue: 0,0:53:25.54,0:53:42.84,csapp,,0,0,0,,hmm
Dialogue: 0,0:53:42.92,0:53:43.86,csapp,,0,0,0,,there we go
Dialogue: 0,0:53:44.90,0:53:49.60,csapp,,0,0,0,,so it reads it reads Elam's number of elements right
Dialogue: 0,0:53:49.90,0:53:55.28,csapp,,0,0,0,,so we've got each of these double word elements with a stride of of stride
Dialogue: 0,0:53:56.62,0:53:58.40,csapp,,0,0,0,,okay so if we have a stride of one
Dialogue: 0,0:54:02.46,0:54:04.18,csapp,,0,0,0,,I know that was kind of redundant huh
Dialogue: 0,0:54:04.44,0:54:06.00,csapp,,0,0,0,,so if we have a stride of one
Dialogue: 0,0:54:09.18,0:54:12.86,csapp,,0,0,0,,then we'll we'll have our loop wills was sort of looped through
Dialogue: 0,0:54:13.62,0:54:17.62,csapp,,0,0,0,,and read these elements until we've read Elam's number of those elements
Dialogue: 0,0:54:18.54,0:54:23.14,csapp,,0,0,0,, okay and then we'll do it again and then that warms up the cache
Dialogue: 0,0:54:23.88,0:54:27.66,csapp,,0,0,0,,  then we do it again and do exactly the same thing
Dialogue: 0,0:54:28.54,0:54:32.82,csapp,,0,0,0,,so if we're doing this with a stride of two then we would be reading
Dialogue: 0,0:54:33.76,0:54:41.80,csapp,,0,0,0,,we would read this word zero or LM - LM 4 and so on
Dialogue: 0,0:54:45.60,0:54:50.02,csapp,,0,0,0,,okay so well then what all we're doing we're just for wide range of strides
Dialogue: 0,0:54:50.84,0:54:53.20,csapp,,0,0,0,,and a wide range of sizes
Dialogue: 0,0:54:53.78,0:55:00.12,csapp,,0,0,0,, we're scanning over this vector and just recording how long it takes to to do that read
Dialogue: 0,0:55:00.56,0:55:04.03,csapp,,0,0,0,,and then convert we convert that into megabytes per second
Dialogue: 0,0:55:05.32,0:55:12.74,csapp,,0,0,0,,and in order to I just wanted to show you this this is we don't need we're not going to go into detail about this but
Dialogue: 0,0:55:13.09,0:55:17.86,csapp,,0,0,0,,this is actually how I generated the the cover on the book and
Dialogue: 0,0:55:18.10,0:55:23.72,csapp,,0,0,0,, in order to in order to use to exploit the parallelism inside the intel processor
Dialogue: 0,0:55:23.86,0:55:27.30,csapp,,0,0,0,,like you learned about last week there's there's a lot of parallel functional units
Dialogue: 0,0:55:27.88,0:55:33.68,csapp,,0,0,0,, in order to exploit those i i did 4x4 loop unrolling
Dialogue: 0,0:55:34.20,0:55:36.96,csapp,,0,0,0,,so I'm actually doing sort of four scans in parallel
Dialogue: 0,0:55:38.66,0:55:41.00,csapp,,0,0,0,,but the general idea is just what I've showed you here
Dialogue: 0,0:55:41.78,0:55:47.34,csapp,,0,0,0,,and this this 4x4 this 4x4 loop unrolling is just an optimization
Dialogue: 0,0:55:47.92,0:55:51.74,csapp,,0,0,0,,but I wanted to show it to you because it actually it's the exact same principles
Dialogue: 0,0:55:51.74,0:55:57.24,csapp,,0,0,0,,you learned about last week Professor Brian talked about code optimization
Dialogue: 0,0:55:58.78,0:56:05.48,csapp,,0,0,0,,so what we do is we we call this test function with these various ranges of Elam's and stride
Dialogue: 0,0:56:06.22,0:56:09.96,csapp,,0,0,0,,and then we measure the performance and we get this beautiful picture
Dialogue: 0,0:56:10.38,0:56:14.44,csapp,,0,0,0,, this beautiful function to me it's beautiful I don't know does it look beautiful to you
Dialogue: 0,0:56:22.40,0:56:24.92,csapp,,0,0,0,,so on the Z
Dialogue: 0,0:56:25.32,0:56:29.90,csapp,,0,0,0,,our z axis is plotting read throughput in megabytes per second
Dialogue: 0,0:56:29.90,0:56:37.58,csapp,,0,0,0,,ranging from 2000 megabytes per second up to 16,000 megabytes per second
Dialogue: 0,0:56:42.66,0:56:48.62,csapp,,0,0,0,,this this axis is measuring is stride
Dialogue: 0,0:56:49.28,0:56:53.00,csapp,,0,0,0,,so going from stride 1 up to stride 12
Dialogue: 0,0:56:55.08,0:57:03.86,csapp,,0,0,0,,and this axis is so as we as we increase stride we're decreasing the spatial locality
Dialogue: 0,0:57:05.54,0:57:06.34,csapp,,0,0,0,, alright
Dialogue: 0,0:57:09.68,0:57:18.00,csapp,,0,0,0,,and this axis is the size axis so we're going from I think 16 K up to 128 megabytes
Dialogue: 0,0:57:18.72,0:57:23.16,csapp,,0,0,0,,so this is the number of elements we're going to read each pass through
Dialogue: 0,0:57:25.60,0:57:29.10,csapp,,0,0,0,,so as we as we increase the size
Dialogue: 0,0:57:30.38,0:57:36.08,csapp,,0,0,0,, we're sort of decreasing the impact of temporal locality because  word
Dialogue: 0,0:57:36.82,0:57:41.80,csapp,,0,0,0,,as we increase the size there's fewer and fewer caches in our hierarchy can hold all that data
Dialogue: 0,0:57:44.62,0:57:49.94,csapp,,0,0,0,, and so this so we've got spatial locality decreasing in this direction
Dialogue: 0,0:57:50.44,0:57:53.06,csapp,,0,0,0,,and temporal locality decreasing in this direction
Dialogue: 0,0:57:54.76,0:57:58.46,csapp,,0,0,0,,so as a programmer what you want to do you want to be up here
Dialogue: 0,0:57:59.86,0:58:02.52,csapp,,0,0,0,,right good spatial locality good temporal locality
Dialogue: 0,0:58:02.92,0:58:07.60,csapp,,0,0,0,,because you can get like 14 gigabytes per second measure agreed throughput
Dialogue: 0,0:58:08.98,0:58:10.70,csapp,,0,0,0,, you don't want to be down here
Dialogue: 0,0:58:11.98,0:58:15.94,csapp,,0,0,0,,which is only about 100 megabytes per second where you're reading out of memory
Dialogue: 0,0:58:16.18,0:58:20.42,csapp,,0,0,0,,  right so the difference between reading all of your data from memory
Dialogue: 0,0:58:21.42,0:58:28.80,csapp,,0,0,0,,and reor reading it from some part of the the caches is huge it's enormous
Dialogue: 0,0:58:29.60,0:58:32.52,csapp,,0,0,0,,ok so because you're 213 students you'll be up here
Dialogue: 0,0:58:33.08,0:58:35.94,csapp,,0,0,0,,and all the students that didn't take 213 they'll be down here
Dialogue: 0,0:58:38.10,0:58:43.04,csapp,,0,0,0,,and I've actually had I've actually had people several people write back
Dialogue: 0,0:58:43.04,0:58:48.40,csapp,,0,0,0,, to tell me about their experiences you know in internships and jobs after they left CMU
Dialogue: 0,0:58:48.94,0:58:51.74,csapp,,0,0,0,, where they were given some code that that was down here
Dialogue: 0,0:58:52.96,0:58:59.52,csapp,,0,0,0,,and they recognized the locality issues and they got it you know better up here or close at least better
Dialogue: 0,0:59:01.18,0:59:07.22,csapp,,0,0,0,, so this is this this picture this so-called memory mountain has all kinds of interesting features
Dialogue: 0,0:59:08.10,0:59:11.40,csapp,,0,0,0,,first of all there's these what I call ridges of temporal locality
Dialogue: 0,0:59:12.02,0:59:15.86,csapp,,0,0,0,,where these ridges see these Ridge lines if you think of this is like a mountain
Dialogue: 0,0:59:15.86,0:59:19.62,csapp,,0,0,0,,you see this Ridgeline and you see this Ridgeline
Dialogue: 0,0:59:20.34,0:59:23.24,csapp,,0,0,0,,and here's another Ridgeline and then here's a here's another one
Dialogue: 0,0:59:23.56,0:59:25.70,csapp,,0,0,0,,these correspond to different levels in the hierarchy
Dialogue: 0,0:59:25.70,0:59:29.58,csapp,,0,0,0,, so this this top Ridgeline is where you're reading directly out of l1
Dialogue: 0,0:59:30.78,0:59:33.16,csapp,,0,0,0,,and it should be perfectly flat and
Dialogue: 0,0:59:33.90,0:59:38.80,csapp,,0,0,0,, it's so fast that we're getting like measurement jitter performance jitter right
Dialogue: 0,0:59:39.90,0:59:45.60,csapp,,0,0,0,,but it's it's and this little drop-off here is a measurement artifact it it should it shouldn't be there
Dialogue: 0,0:59:45.60,0:59:49.22,csapp,,0,0,0,, it should be it should be flat and go all the way to the wall back here
Dialogue: 0,0:59:52.50,0:59:58.48,csapp,,0,0,0,,and then here this this ridge line is where we're accessing l2
Dialogue: 0,0:59:59.16,1:00:00.94,csapp,,0,0,0,,this is where we're accessing l3
Dialogue: 0,1:00:02.00,1:00:05.26,csapp,,0,0,0,,and and here's what we're accessing mostly from memory
Dialogue: 0,1:00:06.38,1:00:08.58,csapp,,0,0,0,,so you have these ridges of temporal locality
Dialogue: 0,1:00:08.94,1:00:12.26,csapp,,0,0,0,,and then you have these slopes of decreasing spatial locality
Dialogue: 0,1:00:13.00,1:00:14.42,csapp,,0,0,0,,so you see the slope here
Dialogue: 0,1:00:15.52,1:00:20.42,csapp,,0,0,0,, as work so as we're moving from the from the top of the slope down to the bottom
Dialogue: 0,1:00:21.84,1:00:28.76,csapp,,0,0,0,,we're decreasing our spatial locality so we're getting less benefit for these blocks  that we're bringing in
Dialogue: 0,1:00:29.27,1:00:33.32,csapp,,0,0,0,,so you can see the we're getting less benefit out of the cost
Dialogue: 0,1:00:33.68,1:00:36.64,csapp,,0,0,0,,that we went through of importing of fetching these blocks
Dialogue: 0,1:00:38.18,1:00:42.28,csapp,,0,0,0,, and once the stride hits the block size
Dialogue: 0,1:00:43.40,1:00:45.58,csapp,,0,0,0,,now every reference is hitting a different block
Dialogue: 0,1:00:46.02,1:00:50.40,csapp,,0,0,0,,and so and then it flattens out then you get you're getting noes benefit from spatial locality
Dialogue: 0,1:00:53.68,1:00:59.50,csapp,,0,0,0,,and similarly here is where this this this slope is where we're reading from l3
Dialogue: 0,1:01:00.44,1:01:05.10,csapp,,0,0,0,,and and and it flattens out always they always flatten out at the
Dialogue: 0,1:01:05.98,1:01:09.80,csapp,,0,0,0,,at the block size which is a stride these are double words right
Dialogue: 0,1:01:10.44,1:01:14.12,csapp,,0,0,0,,so it's stride of eight is 64 bytes
Dialogue: 0,1:01:14.12,1:01:16.66,csapp,,0,0,0,,so once you exceed a stride of eight then you're no longer
Dialogue: 0,1:01:17.18,1:01:20.14,csapp,,0,0,0,,you're missing every time in it in a different block
Dialogue: 0,1:01:23.48,1:01:26.18,csapp,,0,0,0,,there's this this interesting this one puzzled me for a while
Dialogue: 0,1:01:26.94,1:01:32.88,csapp,,0,0,0,,you might be wondering like how come like over here is we increase the size
Dialogue: 0,1:01:33.52,1:01:39.86,csapp,,0,0,0,,we can sort of we're sort of getting the we're sort of as we increase the size
Dialogue: 0,1:01:39.86,1:01:45.60,csapp,,0,0,0,,we're doing most of our references out of caches that are lower in the cache hierarchy
Dialogue: 0,1:01:47.60,1:01:50.68,csapp,,0,0,0,,okay but except when we're doing stride one references s
Dialogue: 0,1:01:51.48,1:01:55.48,csapp,,0,0,0,,you can see all the way up to right at the end
Dialogue: 0,1:01:56.80,1:01:59.76,csapp,,0,0,0,,right before it exceeds the size of l3
Dialogue: 0,1:02:01.24,1:02:01.96,csapp,,0,0,0,,it's flat okay
Dialogue: 0,1:02:05.74,1:02:07.78,csapp,,0,0,0,,and it's it's running at the l2 rate
Dialogue: 0,1:02:08.08,1:02:13.06,csapp,,0,0,0,,alright so here's the l1 rate and then it drops off and then it's running at a constant l2 rate
Dialogue: 0,1:02:13.64,1:02:15.92,csapp,,0,0,0,,until the data no longer fits in l3
Dialogue: 0,1:02:17.24,1:02:20.36,csapp,,0,0,0,,so I think what's going on here is that the the hardware
Dialogue: 0,1:02:21.28,1:02:28.72,csapp,,0,0,0,, the cache the the cache the l2 cache hardware is recognizing  or maybe it's an l1 but
Dialogue: 0,1:02:28.90,1:02:34.28,csapp,,0,0,0,,some some some logic in that in the cache system is recognizing the stride one reference pattern
Dialogue: 0,1:02:35.44,1:02:37.26,csapp,,0,0,0,,right because it sees all the addresses
Dialogue: 0,1:02:37.96,1:02:40.84,csapp,,0,0,0,, it's rough it's recognizing that stride one pattern
Dialogue: 0,1:02:41.58,1:02:46.36,csapp,,0,0,0,,and then it's aggressively prefetching from l3 into l2
Dialogue: 0,1:02:46.90,1:02:51.04,csapp,,0,0,0,,so that those so it's fetching ahead of time it's anticipating
Dialogue: 0,1:02:51.04,1:02:54.52,csapp,,0,0,0,, it's saying look I've gotten five stride one references in a row
Dialogue: 0,1:02:55.14,1:02:58.10,csapp,,0,0,0,,I'm going to go grab a whole bunch of blocks and load them all up
Dialogue: 0,1:02:58.10,1:03:02.66,csapp,,0,0,0,,because by the principle of spatial locality those blocks
Dialogue: 0,1:03:03.32,1:03:05.84,csapp,,0,0,0,, those blocks are going to be referenced in the near future
Dialogue: 0,1:03:07.10,1:03:09.94,csapp,,0,0,0,,so this was really neat and this only happened within the last couple years
Dialogue: 0,1:03:09.94,1:03:12.58,csapp,,0,0,0,,so the Intel engineers are always hard at work
Dialogue: 0,1:03:13.14,1:03:20.70,csapp,,0,0,0,,and maybe by the time the time we do the next   the next edition of the memory Mountain
Dialogue: 0,1:03:22.12,1:03:26.78,csapp,,0,0,0,,those systems will recognize stride 2 and you know other stride pattarns two
Dialogue: 0,1:03:27.72,1:03:31.04,csapp,,0,0,0,,- but from this data it appears that it's only recognizing stride one
Dialogue: 0,1:03:36.16,1:03:44.42,csapp,,0,0,0,,ok so you can real you we can improve the spatial and temporal locality of our programs
Dialogue: 0,1:03:45.84,1:03:51.52,csapp,,0,0,0,, in several different ways that one way to improve the spatial locality is to rearrange loops
Dialogue: 0,1:03:52.64,1:03:55.08,csapp,,0,0,0,,and I'll use matrix multiplication as an example
Dialogue: 0,1:03:56.48,1:04:03.58,csapp,,0,0,0,,so here's a sort of a simple matrix multiplication in code
Dialogue: 0,1:04:03.58,1:04:08.14,csapp,,0,0,0,,where we're multiplying a times B and adding it
Dialogue: 0,1:04:08.58,1:04:13.82,csapp,,0,0,0,,we're taking what's in of the IJ element of C
Dialogue: 0,1:04:15.18,1:04:24.72,csapp,,0,0,0,,and then to that we're adding the sum the inner product of Rho I of a and the row J a column J of B
Dialogue: 0,1:04:26.06,1:04:30.28,csapp,,0,0,0,,okay and then so we're going through and for each IJ in this matrix C
Dialogue: 0,1:04:30.30,1:04:35.96,csapp,,0,0,0,,we're computing an inner product and then creating that sum
Dialogue: 0,1:04:38.20,1:04:42.64,csapp,,0,0,0,,so we can actually turns out there's a lot of different ways to do matrix multiply
Dialogue: 0,1:04:43.76,1:04:46.08,csapp,,0,0,0,,and this is we can permute these these loops
Dialogue: 0,1:04:47.36,1:04:50.50,csapp,,0,0,0,, in any of six different possible permutations
Dialogue: 0,1:04:51.44,1:04:56.10,csapp,,0,0,0,,so this is a permutation where it's I followed by J followed by K
Dialogue: 0,1:04:56.10,1:05:00.48,csapp,,0,0,0,,but five other possibilities are feasible
Dialogue: 0,1:05:01.94,1:05:05.56,csapp,,0,0,0,,and so we can actually analyze those those different permutations
Dialogue: 0,1:05:05.90,1:05:08.24,csapp,,0,0,0,,and predict which one will have the best performance
Dialogue: 0,1:05:10.24,1:05:12.02,csapp,,0,0,0,, okay so what we'll do is we'll look at the inner loop
Dialogue: 0,1:05:15.56,1:05:18.02,csapp,,0,0,0,,and we'll look at the access pattern of the inner loops
Dialogue: 0,1:05:18.02,1:05:22.34,csapp,,0,0,0,,and it's in the access pattern on arrays C a and B
Dialogue: 0,1:05:25.22,1:05:30.94,csapp,,0,0,0,,okay so let's look at the ijk implementation that I just showed you
Dialogue: 0,1:05:31.76,1:05:33.60,csapp,,0,0,0,, so as always we focus on the inner loop
Dialogue: 0,1:05:35.38,1:05:41.54,csapp,,0,0,0,,and if you notice this inner loop is doing a row wise access of column a
Dialogue: 0,1:05:42.98,1:05:47.18,csapp,,0,0,0,, and a column wise access I'm sorry a row wise access of array a
Dialogue: 0,1:05:47.82,1:05:51.00,csapp,,0,0,0,, and column wise access of a row B
Dialogue: 0,1:05:52.24,1:05:56.62,csapp,,0,0,0,,so row wise of a column wise of B we don't really care about C
Dialogue: 0,1:05:56.62,1:05:59.82,csapp,,0,0,0,, because it's out it's not in the inner loop okay so just ignore that
Dialogue: 0,1:06:01.88,1:06:08.26,csapp,,0,0,0,, so given our assumption that we can hold in this case we're assuming that
Dialogue: 0,1:06:08.26,1:06:13.80,csapp,,0,0,0,, we can hold for four of these integer elements in a in one block
Dialogue: 0,1:06:15.52,1:06:20.22,csapp,,0,0,0,,so the row wise access which has good spatial locality will miss one every four accesses
Dialogue: 0,1:06:21.14,1:06:24.68,csapp,,0,0,0,, okay the very first reference will miss and then the next three will hit
Dialogue: 0,1:06:25.58,1:06:27.76,csapp,,0,0,0,,and then the next reference after that will hit a new block
Dialogue: 0,1:06:28.62,1:06:33.24,csapp,,0,0,0,,okay so so one out of four references to a will miss
Dialogue: 0,1:06:33.94,1:06:37.60,csapp,,0,0,0,,but because the access pattern for B is column wise every
Dialogue: 0,1:06:38.50,1:06:41.22,csapp,,0,0,0,,every act every reference to B will miss
Dialogue: 0,1:06:42.46,1:06:45.84,csapp,,0,0,0,,okay so the average number of misses per loop iteration is one point two five
Dialogue: 0,1:06:47.30,1:06:50.92,csapp,,0,0,0,, okay the ji K version is exactly the same pattern
Dialogue: 0,1:06:55.08,1:06:57.78,csapp,,0,0,0,, ki J is a little different here
Dialogue: 0,1:06:59.22,1:07:01.34,csapp,,0,0,0,,we're doing row wise access of B
Dialogue: 0,1:07:03.12,1:07:05.64,csapp,,0,0,0,,and a row wise access of C so that's good right
Dialogue: 0,1:07:06.00,1:07:09.30,csapp,,0,0,0,, so now we've got stride one accesses on both B and C
Dialogue: 0,1:07:10.16,1:07:13.58,csapp,,0,0,0,,and the reference to a is outside of the loop so we don't care about it
Dialogue: 0,1:07:14.84,1:07:18.96,csapp,,0,0,0,, so so both B and C will miss one quarter of the time
Dialogue: 0,1:07:20.40,1:07:24.34,csapp,,0,0,0,,okay so the total average number of misses per loop iteration will be 0.5
Dialogue: 0,1:07:25.40,1:07:29.70,csapp,,0,0,0,, that's pretty good and I KJ has the same similar behavior
Dialogue: 0,1:07:30.90,1:07:33.28,csapp,,0,0,0,,now J ki is sort of the exact opposite
Dialogue: 0,1:07:33.28,1:07:37.74,csapp,,0,0,0,,j ki does column wise access of a
Dialogue: 0,1:07:38.48,1:07:42.20,csapp,,0,0,0,,and column-wise access of c so right we know that's a stinker right
Dialogue: 0,1:07:42.96,1:07:51.62,csapp,,0,0,0,,and and we qualitative well you know it's bad and we can compute that it will miss a one time per loop iteration
Dialogue: 0,1:07:52.46,1:07:55.36,csapp,,0,0,0,, so that will be two total of two misses per iteration
Dialogue: 0,1:07:55.54,1:07:57.90,csapp,,0,0,0,,and kji has the same bad pattern
Dialogue: 0,1:07:58.86,1:08:01.02,csapp,,0,0,0,,okay so if we look at all these permutations
Dialogue: 0,1:08:02.42,1:08:08.68,csapp,,0,0,0,,you can see that ijk and ji k miss 1.25 have 1.25 mrs.
Dialogue: 0,1:08:09.72,1:08:13.86,csapp,,0,0,0,,K IJ has 0.5 misses and j ki has two misses
Dialogue: 0,1:08:15.06,1:08:20.92,csapp,,0,0,0,,so clearly it looks like ki J and its brethren are the best option
Dialogue: 0,1:08:20.92,1:08:25.56,csapp,,0,0,0,, the only difference is that k k IJ has this additional store
Dialogue: 0,1:08:25.56,1:08:29.54,csapp,,0,0,0,,so there might be a question that is that going to create is that going to slow things down
Dialogue: 0,1:08:30.74,1:08:37.20,csapp,,0,0,0,,well it turns out in systems in any kind storage systems rights
Dialogue: 0,1:08:37.74,1:08:39.46,csapp,,0,0,0,, are much easier to deal with them reads
Dialogue: 0,1:08:40.94,1:08:42.90,csapp,,0,0,0,,can you think about why that might be true
Dialogue: 0,1:08:44.28,1:08:47.32,csapp,,0,0,0,,so writes you have a lot more flexibility than you do with reads
Dialogue: 0,1:08:53.06,1:08:57.26,csapp,,0,0,0,,I mean yes
Dialogue: 0,1:08:57.28,1:09:02.78,csapp,,0,0,0,,that's exactly so you can you have options you can do you can write back defer you can defer writing
Dialogue: 0,1:09:03.60,1:09:07.04,csapp,,0,0,0,,until the value the value that you're written is actually used
Dialogue: 0,1:09:07.38,1:09:09.04,csapp,,0,0,0,,but when you read an item you're stuck
Dialogue: 0,1:09:10.02,1:09:12.64,csapp,,0,0,0,,you can't do anything until until you get that data
Dialogue: 0,1:09:13.08,1:09:17.30,csapp,,0,0,0,,so it turns out that that rights don't really that this additional store doesn't really hurt us
Dialogue: 0,1:09:18.54,1:09:22.22,csapp,,0,0,0,,and so when we measure these on a modern system
Dialogue: 0,1:09:22.66,1:09:29.34,csapp,,0,0,0,,you can see that that the Kate kij which has the the fewest number of misses
Dialogue: 0,1:09:29.82,1:09:36.32,csapp,,0,0,0,, has you see we're getting like one miss what we're plotting here is cycles per interloop iteration
Dialogue: 0,1:09:36.32,1:09:40.50,csapp,,0,0,0,, so each each iteration is taking about one cycle which is really good
Dialogue: 0,1:09:41.54,1:09:46.30,csapp,,0,0,0,,this i JK pattern which is kind of the intermediate 1.2 misses
Dialogue: 0,1:09:47.00,1:09:51.98,csapp,,0,0,0,,that's sort of in between and the JK I which has two misses per iteration is the worst
Dialogue: 0,1:09:52.86,1:09:57.16,csapp,,0,0,0,,ok so what's interesting is we could actually just by doing a little bit of analysis
Dialogue: 0,1:09:57.88,1:10:02.08,csapp,,0,0,0,, simple analysis we could actually predict what this what this graph would look like
Dialogue: 0,1:10:03.74,1:10:08.16,csapp,,0,0,0,, okay in the last last ten minutes of the class
Dialogue: 0,1:10:08.46,1:10:11.28,csapp,,0,0,0,, we're going to look at how to improve temporal locality
Dialogue: 0,1:10:12.04,1:10:15.00,csapp,,0,0,0,, now so what we did with with when we rearranged our loops
Dialogue: 0,1:10:15.38,1:10:20.26,csapp,,0,0,0,, with in the matrix multiplication what we were doing was in improving our spatial locality right
Dialogue: 0,1:10:21.30,1:10:24.96,csapp,,0,0,0,,but we didn't we didn't really do anything to improve the temporal locality
Dialogue: 0,1:10:25.58,1:10:28.58,csapp,,0,0,0,, to improve temporal locality you have to use a technique called blocking
Dialogue: 0,1:10:29.50,1:10:34.78,csapp,,0,0,0,,and this is important to understand because you're going to need it in your cache lab for one thing
Dialogue: 0,1:10:35.18,1:10:37.02,csapp,,0,0,0,, but it's also a very general technique
Dialogue: 0,1:10:37.50,1:10:40.82,csapp,,0,0,0,,anytime you need any time you're having issues with temporal locality
Dialogue: 0,1:10:42.08,1:10:42.82,csapp,,0,0,0,,okay so
Dialogue: 0,1:10:46.02,1:10:51.00,csapp,,0,0,0,, we're not going to go into too much detail this code but what I did I rewrote the matrix multiply
Dialogue: 0,1:10:53.06,1:10:58.18,csapp,,0,0,0,,so that it operates you know a two-dimensional matrix that you can really just think of it as a contiguous array of bytes
Dialogue: 0,1:10:58.68,1:11:03.02,csapp,,0,0,0,,so I just rewrote this code to operate on a contiguous array one-dimensional array
Dialogue: 0,1:11:03.60,1:11:06.04,csapp,,0,0,0,,and then I'm doing the indexing explicitly here
Dialogue: 0,1:11:06.30,1:11:11.22,csapp,,0,0,0,,so here at CI times n plus J this is an N by n matrix
Dialogue: 0,1:11:11.22,1:11:16.30,csapp,,0,0,0,,so what I'm doing is I'm I'm accessing the I'm computing where the I throw starts
Dialogue: 0,1:11:16.92,1:11:21.66,csapp,,0,0,0,, and then I'm going to the J column of that row and then accessing that element
Dialogue: 0,1:11:27.50,1:11:30.08,csapp,,0,0,0,,all right so let's but it's the same idea as before
Dialogue: 0,1:11:31.04,1:11:38.16,csapp,,0,0,0,, so let's look at the Miss rate for this this is just our original this is our original unblocked matrix multiplied
Dialogue: 0,1:11:39.34,1:11:44.78,csapp,,0,0,0,,so what we're doing is we're we're computing C 0 0
Dialogue: 0,1:11:45.46,1:11:50.24,csapp,,0,0,0,, and we're doing that by taking an inner product of row 0 and column 0
Dialogue: 0,1:11:53.80,1:11:59.80,csapp,,0,0,0,,so if you look at the we're assuming that the cache the cache blocks holds eight doubles
Dialogue: 0,1:12:00.06,1:12:04.64,csapp,,0,0,0,,and that the matrix elements are doubles then we're going to miss one eighth of the time
Dialogue: 0,1:12:05.96,1:12:08.06,csapp,,0,0,0,, okay so in the first iteration
Dialogue: 0,1:12:11.42,1:12:16.22,csapp,,0,0,0,,we're going to miss the first iteration does n of these things
Dialogue: 0,1:12:16.66,1:12:19.34,csapp,,0,0,0,,and since we're missing n over eight of the time
Dialogue: 0,1:12:19.72,1:12:25.12,csapp,,0,0,0,,what we're missing one block for every eight eight references
Dialogue: 0,1:12:28.30,1:12:32.48,csapp,,0,0,0,,for each for the first iteration we're going to miss n over eight
Dialogue: 0,1:12:34.22,1:12:37.44,csapp,,0,0,0,,and since there's n for each element for each block I'm sorry
Dialogue: 0,1:12:37.90,1:12:45.56,csapp,,0,0,0,,and then oh so this is the number of blocks and the number of misses and then we have n elements
Dialogue: 0,1:12:45.98,1:12:52.46,csapp,,0,0,0,,so that the total number of misses is nine over n divided by eight misses for the first iteration
Dialogue: 0,1:12:54.24,1:12:58.56,csapp,,0,0,0,,okay the second iteration will have the same number of misses
Dialogue: 0,1:12:58.56,1:13:01.92,csapp,,0,0,0,,because of our assumptions about the the size of this array
Dialogue: 0,1:13:02.36,1:13:06.00,csapp,,0,0,0,,so this these rows are way too big to fit in the cache
Dialogue: 0,1:13:06.20,1:13:09.46,csapp,,0,0,0,, so we never get any we don't get any temporal locality
Dialogue: 0,1:13:11.24,1:13:18.30,csapp,,0,0,0,,okay so the total number of misses is nine n over eight times the number of elements that we're updating which is N squared
Dialogue: 0,1:13:18.94,1:13:23.20,csapp,,0,0,0,,okay so our total misses is nine over 8 times n cubed
Dialogue: 0,1:13:25.62,1:13:28.38,csapp,,0,0,0,,now let's rewrite the code to use blocking and so
Dialogue: 0,1:13:30.44,1:13:31.94,csapp,,0,0,0,, you can look at this code later
Dialogue: 0,1:13:32.40,1:13:36.78,csapp,,0,0,0,,but it's much simpler just just to look at it pictorially
Dialogue: 0,1:13:36.80,1:13:42.06,csapp,,0,0,0,,so what what we're doing instead of updating one element at a time
Dialogue: 0,1:13:43.30,1:13:46.82,csapp,,0,0,0,, we're updating a sub block a B by B sub block
Dialogue: 0,1:13:48.96,1:13:52.76,csapp,,0,0,0,,and we're doing that just totally analogously to when
Dialogue: 0,1:13:53.22,1:13:55.38,csapp,,0,0,0,,our original case where B equal 1
Dialogue: 0,1:13:56.54,1:14:04.10,csapp,,0,0,0,,this this B by B sub block and C is computed by taking an inner product of the sub blocks
Dialogue: 0,1:14:05.66,1:14:11.66,csapp,,0,0,0,,of a set of sub blocks  in an a with a set of sub blocks in B
Dialogue: 0,1:14:12.32,1:14:15.48,csapp,,0,0,0,,and for each one of those we're doing a little mini matrix multiplication
Dialogue: 0,1:14:15.48,1:14:21.42,csapp,,0,0,0,,so we're taking we're taking this sub block times this sub block
Dialogue: 0,1:14:22.62,1:14:29.26,csapp,,0,0,0,,plus the second sub block of a times the second sub block of of B
Dialogue: 0,1:14:30.06,1:14:34.22,csapp,,0,0,0,,plus the third sub block of a times the third sub block of B and so on
Dialogue: 0,1:14:34.88,1:14:37.38,csapp,,0,0,0,,okay so we're doing the same inner product  operation
Dialogue: 0,1:14:37.38,1:14:42.50,csapp,,0,0,0,,but instead of scalars we're doing it with these little sub these little tiny matrices
Dialogue: 0,1:14:45.82,1:14:50.76,csapp,,0,0,0,, ok all right so let's look at let's look at what happens to the Miss rate when we do this
Dialogue: 0,1:14:53.80,1:15:03.38,csapp,,0,0,0,,so there's there's n over B blocks in in any row or column
Dialogue: 0,1:15:05.08,1:15:11.26,csapp,,0,0,0,,and since there's B squared items in each block B times B
Dialogue: 0,1:15:11.76,1:15:14.30,csapp,,0,0,0,,there's B squared over 8 misses for each block
Dialogue: 0,1:15:19.66,1:15:25.60,csapp,,0,0,0,,okay and so then and then since there's there's n over B blocks in each matrix and there's two matrices
Dialogue: 0,1:15:26.30,1:15:34.82,csapp,,0,0,0,,there's two to n over B times B squared over 8 misses for this first iteration
Dialogue: 0,1:15:34.82,1:15:38.66,csapp,,0,0,0,,so that that works out to be an NB divided by 4 and
Dialogue: 0,1:15:41.50,1:15:46.30,csapp,,0,0,0,,and the second iteration has the same as the same miss sort of same miss rate
Dialogue: 0,1:15:47.08,1:15:50.70,csapp,,0,0,0,,so the total number of misses is the number of the number of
Dialogue: 0,1:15:51.02,1:15:54.20,csapp,,0,0,0,,misses for each iteration
Dialogue: 0,1:15:55.44,1:16:01.22,csapp,,0,0,0,,x times the number of elements in C that we're updating
Dialogue: 0,1:16:01.56,1:16:04.06,csapp,,0,0,0,,okay which is n over B squared
Dialogue: 0,1:16:05.80,1:16:10.20,csapp,,0,0,0,,so that all works out too it's still in its n cube divided by 4 B
Dialogue: 0,1:16:12.86,1:16:19.48,csapp,,0,0,0,,so in our first case with no blocking although that the number of misses is asymptotically the same
Dialogue: 0,1:16:20.06,1:16:25.40,csapp,,0,0,0,, but there's this pretty this big difference in the constant factor so for no blocking it's 9 over 8
Dialogue: 0,1:16:26.26,1:16:31.08,csapp,,0,0,0,,for blocking it's 1 over 4b we're now we can we can just sort of drive that down
Dialogue: 0,1:16:31.52,1:16:36.38,csapp,,0,0,0,, by by increasing the block size so this gives us some some control
Dialogue: 0,1:16:39.02,1:16:44.68,csapp,,0,0,0,,but we still we have we can't make the block the blocks too big because we need to fit three blocks
Dialogue: 0,1:16:45.44,1:16:47.46,csapp,,0,0,0,, in cache at any one point in time
Dialogue: 0,1:16:50.44,1:16:52.80,csapp,,0,0,0,,ok so the reason this is a dramatic difference right
Dialogue: 0,1:16:54.34,1:16:59.80,csapp,,0,0,0,, and the reason for this is that by doing the blocking we're sort of exploiting
Dialogue: 0,1:17:00.54,1:17:04.74,csapp,,0,0,0,, once we load a block into memory we're sort of reusing its items over and over again
Dialogue: 0,1:17:04.74,1:17:06.74,csapp,,0,0,0,,so we're exploiting more temporal locality
Dialogue: 0,1:17:08.30,1:17:12.68,csapp,,0,0,0,,and matrix multiplication has this into this implicit locality
Dialogue: 0,1:17:12.68,1:17:18.88,csapp,,0,0,0,,because the computation is order n cubed but the size of the data is n squared
Dialogue: 0,1:17:19.98,1:17:23.36,csapp,,0,0,0,,right so so we must be reusing some data items
Dialogue: 0,1:17:24.18,1:17:29.71,csapp,,0,0,0,,right the problem with our scalar approach is that we we were when we were reusing them they weren't in the cache
Dialogue: 0,1:17:29.71,1:17:32.67,csapp,,0,0,0,,ok
Dialogue: 0,1:17:35.66,1:17:40.00,csapp,,0,0,0,,all right so the point that I wanted to make with you is that 
Dialogue: 0,1:17:40.72,1:17:47.06,csapp,,0,0,0,,cache memories although they're they're sort of built-in automatic hardware storage devices 
Dialogue: 0,1:17:47.72,1:17:49.60,csapp,,0,0,0,,and you can't really control them 
Dialogue: 0,1:17:50.04,1:17:54.20,csapp,,0,0,0,,if you know about them you can take advantage of your knowledge 
Dialogue: 0,1:17:54.68,1:17:58.16,csapp,,0,0,0,,and exploit exploit them and make your code run faster 
Dialogue: 0,1:17:59.36,1:18:03.14,csapp,,0,0,0,,okay and the way you do this is like I said focus on the inner loops 
Dialogue: 0,1:18:05.84,1:18:10.00,csapp,,0,0,0,,do is try to do try to do accesses that our stride one 
Dialogue: 0,1:18:10.66,1:18:14.02,csapp,,0,0,0,,and try to maximize to to maximize spatial locality
Dialogue: 0,1:18:14.40,1:18:18.42,csapp,,0,0,0,, and try to maximize temporal locality by reusing local variables
Dialogue: 0,1:18:18.50,1:18:20.08,csapp,,0,0,0,,  which can then be put into registers 
Dialogue: 0,1:18:21.90,1:18:26.46,csapp,,0,0,0,,okay so that's it for today good luck with your attack lab if you haven't finished it and 
Dialogue: 0,1:18:27.18,1:18:32.30,csapp,,0,0,0,,don't forget to get started on cache lab this weekend
